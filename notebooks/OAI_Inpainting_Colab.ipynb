{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”¬ OAI X-ray Inpainting - Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/johnreynolds3d/OAI-inpainting/blob/master/notebooks/OAI_Inpainting_Colab.ipynb)\n",
    "\n",
    "**Comprehensive testing and training of 9+ inpainting model variants on OAI knee X-ray data**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ What This Notebook Does\n",
    "\n",
    "This notebook tests and trains state-of-the-art image inpainting models on OAI (Osteoarthritis Initiative) knee X-ray data:\n",
    "\n",
    "### ğŸ“Š Model Variants Available:\n",
    "- **AOT-GAN**: CelebA-HQ, Places2, OAI-trained\n",
    "- **ICT**: FFHQ, ImageNet, Places2_Nature, OAI-trained  \n",
    "- **RePaint**: CelebA-HQ, ImageNet, Places2\n",
    "\n",
    "**Total: 9 different model variants** tested on your OAI data!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Quick Start (5 Simple Steps)\n",
    "\n",
    "### 1ï¸âƒ£ **Setup Environment**\n",
    "- Run: \"Check GPU availability\"\n",
    "- Run: \"Alternative setup method (if Git fails)\"\n",
    "â†’ Clones repo, creates symlinks, installs dependencies\n",
    "\n",
    "### 2ï¸âƒ£ **Mount Google Drive**\n",
    "- Run: \"Mount Google Drive and setup data\"\n",
    "â†’ Makes your OAI_untracked folder accessible\n",
    "\n",
    "### 3ï¸âƒ£ **Verify Setup**\n",
    "- Run: \"Verify installation and setup\"\n",
    "â†’ Quick check that imports work\n",
    "\n",
    "### 4ï¸âƒ£ **Generate Dataset Splits** (First time only)\n",
    "- Run: \"GENERATE DATASET SPLITS\"\n",
    "â†’ Creates **perfectly balanced** train/valid/test splits using **ALL 539 images**\n",
    "â†’ 80/10/10 split with equal low/high BMD representation\n",
    "â†’ Creates subset_4 (4 test images) for quick testing\n",
    "\n",
    "### 5ï¸âƒ£ **Test All Models**\n",
    "- Run: \"PIPELINE RUNNER SETUP\" (imports functions)\n",
    "- Run: \"QUICK START - Test ALL Model Variants\"\n",
    "â†’ Tests all 9 models in ~30-60 minutes\n",
    "\n",
    "**Done!** Results saved to Google Drive automatically.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Data Organization\n",
    "\n",
    "**Recommended setup:**\n",
    "- âœ… **Code**: Cloned from GitHub (always up-to-date)\n",
    "- âœ… **Data**: Stored in Google Drive (persistent across sessions)\n",
    "- âœ… **Results**: Generated in Colab (downloadable as ZIP)\n",
    "\n",
    "**Required data structure:**\n",
    "```\n",
    "OAI_untracked/\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ oai/\n",
    "â”‚   â”‚   â”œâ”€â”€ img/          # 539 PNG X-ray images\n",
    "â”‚   â”‚   â”œâ”€â”€ data.csv      # BMD values for each image\n",
    "â”‚   â”‚   â””â”€â”€ split.py      # Balanced split generator\n",
    "â”‚   â””â”€â”€ pretrained/       # Model checkpoint files\n",
    "â”‚       â”œâ”€â”€ aot-gan/\n",
    "â”‚       â”œâ”€â”€ ict/\n",
    "â”‚       â””â”€â”€ repaint/\n",
    "```\n",
    "\n",
    "**ğŸ“Š New Balanced Split (Oct 2025):**\n",
    "- âœ… Uses **ALL 539 images** (previously only ~268)\n",
    "- âœ… **80% train** (431 images), **10% val** (53 images), **10% test** (55 images)\n",
    "- âœ… **Perfectly balanced**: Equal low/high BMD in each split\n",
    "- âœ… **Mutually exclusive**: No image overlap between splits\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Usage Modes\n",
    "\n",
    "### Mode 1: **Quick Testing** (Recommended for first time)\n",
    "- â±ï¸ Time: ~30-60 minutes\n",
    "- ğŸ¯ Purpose: Test all pretrained models on 4 sample images\n",
    "- ğŸ“Š Output: Comparison of all 9 model variants\n",
    "- ğŸ’» Run: Cell 11 (Comprehensive Test)\n",
    "\n",
    "### Mode 2: **Full Training** (Advanced)\n",
    "- â±ï¸ Time: 6-8 hours\n",
    "- ğŸ¯ Purpose: Train new models on full OAI dataset\n",
    "- ğŸ“Š Output: New trained models + evaluation\n",
    "- ğŸ’» Run: Cell 14 (Training Pipeline)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and setup data\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    print(\"âœ… Google Drive mounted successfully\")\n",
    "\n",
    "    # Check for OAI data in Google Drive\n",
    "    oai_drive_path = Path(\"/content/drive/MyDrive/Colab Notebooks/OAI_untracked\")\n",
    "    if oai_drive_path.exists():\n",
    "        print(f\"âœ… OAI data found in Google Drive: {oai_drive_path}\")\n",
    "\n",
    "        # Create symlinks to Google Drive data\n",
    "        data_dir = Path(\"data\")\n",
    "        if not data_dir.exists():\n",
    "            data_dir.mkdir()\n",
    "\n",
    "        # Link to Google Drive data\n",
    "        oai_link = data_dir / \"oai\"\n",
    "        if not oai_link.exists():\n",
    "            oai_link.symlink_to(oai_drive_path)\n",
    "            print(\"ğŸ”— Created symlink to Google Drive OAI data\")\n",
    "    else:\n",
    "        print(\"âŒ OAI data not found in Google Drive\")\n",
    "        print(\n",
    "            \"ğŸ’¡ Please ensure your data is in: /content/drive/MyDrive/Colab Notebooks/OAI_untracked\"\n",
    "        )\n",
    "\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Google Colab not detected - skipping Drive mount\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error mounting Google Drive: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative setup method (if Git fails)\n",
    "import os\n",
    "import subprocess\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def setup_repository_alternative():\n",
    "    \"\"\"Alternative method to setup repository without Git\"\"\"\n",
    "    print(\"ğŸ”„ Using alternative setup method...\")\n",
    "\n",
    "    # IMPORTANT: Navigate to Google Drive to maintain sibling directory structure\n",
    "    # This ensures relative symlinks work (data -> ../OAI_untracked/data/)\n",
    "    # Making it portable between local and Colab environments\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "\n",
    "        colab_notebooks = Path(\"/content/drive/MyDrive/Colab Notebooks\")\n",
    "        if colab_notebooks.exists():\n",
    "            os.chdir(colab_notebooks)\n",
    "            print(f\"âœ… Working directory: {Path.cwd()}\")\n",
    "            print(\"ğŸ’¡ Using relative paths for portability\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Google Drive not mounted or path not found\")\n",
    "            print(f\"ğŸ“ Current directory: {Path.cwd()}\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ Not in Colab environment - using current directory\")\n",
    "        print(f\"ğŸ“ Current directory: {Path.cwd()}\")\n",
    "\n",
    "    if not Path(\"OAI-inpainting\").exists():\n",
    "        print(\"ğŸ“¥ Downloading repository as ZIP...\")\n",
    "        try:\n",
    "            # Download the repository as ZIP\n",
    "            zip_url = \"https://github.com/johnreynolds3d/OAI-inpainting/archive/refs/heads/master.zip\"\n",
    "            zip_path = \"OAI-inpainting-master.zip\"\n",
    "\n",
    "            print(f\"ğŸ“¥ Downloading from: {zip_url}\")\n",
    "            urllib.request.urlretrieve(zip_url, zip_path)\n",
    "\n",
    "            # Extract the ZIP file\n",
    "            print(\"ğŸ“¦ Extracting repository...\")\n",
    "            with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(\".\")\n",
    "\n",
    "            # Rename the extracted folder\n",
    "            if Path(\"OAI-inpainting-master\").exists():\n",
    "                if Path(\"OAI-inpainting\").exists():\n",
    "                    import shutil\n",
    "\n",
    "                    shutil.rmtree(\"OAI-inpainting\")\n",
    "                Path(\"OAI-inpainting-master\").rename(\"OAI-inpainting\")\n",
    "\n",
    "            # Clean up ZIP file\n",
    "            Path(zip_path).unlink()\n",
    "            print(\"âœ… Repository downloaded and extracted successfully\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Download failed: {e}\")\n",
    "            print(\"ğŸ’¡ Please check your internet connection and try again\")\n",
    "            return False\n",
    "\n",
    "    # Change to project directory\n",
    "    os.chdir(\"OAI-inpainting\")\n",
    "    print(f\"ğŸ“‚ Current directory: {Path.cwd()}\")\n",
    "\n",
    "    # Create relative symlinks (portable between local and Colab)\n",
    "    print(\"\\nğŸ”— Setting up portable symlinks...\")\n",
    "\n",
    "    # Remove any broken files that might have been cloned from Git\n",
    "    for name in [\"data\", \"results\"]:\n",
    "        path = Path(name)\n",
    "        if path.is_file():  # Broken symlink tracked as file\n",
    "            path.unlink()\n",
    "            print(f\"ğŸ—‘ï¸  Removed broken {name} file\")\n",
    "\n",
    "    # Create data symlink using relative path (portable!)\n",
    "    data_dir = Path(\"data\")\n",
    "    relative_data_path = Path(\"../OAI_untracked/data\")\n",
    "\n",
    "    if not data_dir.exists():\n",
    "        if relative_data_path.exists():\n",
    "            data_dir.symlink_to(relative_data_path)\n",
    "            print(\"âœ… Created data symlink -> ../OAI_untracked/data/ (relative)\")\n",
    "        else:\n",
    "            print(\"âš ï¸ OAI_untracked/data not found as sibling directory\")\n",
    "            print(\n",
    "                \"ğŸ’¡ Expected structure: parent_dir/OAI-inpainting/ and parent_dir/OAI_untracked/\"\n",
    "            )\n",
    "    elif data_dir.is_symlink():\n",
    "        print(\"âœ… Data symlink already exists (relative)\")\n",
    "\n",
    "    # For results, create as REAL directory (not symlink)\n",
    "    # This avoids Google Drive/filesystem restrictions on nested directory creation\n",
    "    # Results can be copied to Drive later if needed for persistence\n",
    "    results_dir = Path(\"results\")\n",
    "    if results_dir.is_symlink():\n",
    "        # Remove symlink and create real directory\n",
    "        results_dir.unlink()\n",
    "        results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(\"âœ… Replaced results symlink with real directory (better performance)\")\n",
    "    elif not results_dir.exists():\n",
    "        results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(\"âœ… Created results directory\")\n",
    "    else:\n",
    "        print(\"âœ… Results directory already exists\")\n",
    "\n",
    "    # Install core dependencies manually\n",
    "    print(\"\\nğŸ“¦ Installing core dependencies...\")\n",
    "    core_deps = [\n",
    "        \"torch\",\n",
    "        \"torchvision\",\n",
    "        \"numpy\",\n",
    "        \"opencv-python\",\n",
    "        \"pillow\",\n",
    "        \"scikit-image\",\n",
    "        \"scipy\",\n",
    "        \"pandas\",\n",
    "        \"matplotlib\",\n",
    "        \"seaborn\",\n",
    "        \"pyyaml\",\n",
    "        \"tqdm\",\n",
    "        \"tensorboard\",\n",
    "        \"wandb\",\n",
    "        \"scikit-learn\",\n",
    "    ]\n",
    "\n",
    "    for dep in core_deps:\n",
    "        try:\n",
    "            subprocess.run([\"pip\", \"install\", dep], check=True, capture_output=True)\n",
    "            print(f\"âœ… Installed {dep}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"âš ï¸ Failed to install {dep}\")\n",
    "\n",
    "    print(\"\\nâœ… Alternative setup complete!\")\n",
    "    print(f\"ğŸ“ Project location: {Path.cwd()}\")\n",
    "    print(\n",
    "        f\"ğŸ“ Data location: {Path('data').resolve() if Path('data').exists() else 'Not linked'}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"ğŸ“ Results location: {Path('results').resolve() if Path('results').exists() else 'Not linked'}\"\n",
    "    )\n",
    "    return True\n",
    "\n",
    "\n",
    "# Run alternative setup\n",
    "setup_repository_alternative()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Troubleshooting\n",
    "\n",
    "If you encounter issues with the setup:\n",
    "\n",
    "1. **Git not available**: The notebook will automatically fall back to downloading the repository as a ZIP file\n",
    "2. **Dependency installation fails**: Core dependencies will be installed individually\n",
    "3. **Permission errors**: Restart the runtime and try again\n",
    "4. **Import errors**: Make sure you're in the correct directory (`OAI-inpainting`)\n",
    "5. **NotADirectoryError**: Run the \"FIX: Results Directory Issue\" cell below\n",
    "\n",
    "**Quick fixes:**\n",
    "- **Fix results directory**: Run the next cell (Results Directory Fix)\n",
    "- Restart runtime: `Runtime â†’ Restart runtime`\n",
    "- Check directory: `!pwd`\n",
    "- List files: `!ls -la`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ FIX: Results Directory Issue\n",
    "# Run this cell if you get \"NotADirectoryError\" when running tests\n",
    "# This fixes the results directory by converting it from a symlink to a real directory\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ”§ Fixing results directory...\")\n",
    "\n",
    "# Try to navigate to project directory\n",
    "try:\n",
    "    project_dirs = [\n",
    "        Path(\"/content/drive/MyDrive/Colab Notebooks/OAI-inpainting\"),\n",
    "        Path(\"/content/OAI-inpainting\"),\n",
    "        Path(\"OAI-inpainting\"),\n",
    "        Path.cwd(),\n",
    "    ]\n",
    "\n",
    "    for project_dir in project_dirs:\n",
    "        if project_dir.exists() and (project_dir / \"models\").exists():\n",
    "            os.chdir(project_dir)\n",
    "            print(f\"ğŸ“ Working directory: {os.getcwd()}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"âš ï¸ Could not find OAI-inpainting directory\")\n",
    "        print(f\"ğŸ“ Current directory: {os.getcwd()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error navigating: {e}\")\n",
    "    print(f\"ğŸ“ Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check and fix results directory\n",
    "results = Path(\"results\")\n",
    "\n",
    "if results.is_symlink():\n",
    "    target = os.readlink(results)\n",
    "    print(f\"âš ï¸ Found symlink: results -> {target}\")\n",
    "    results.unlink()\n",
    "    print(\"ğŸ—‘ï¸ Removed symlink\")\n",
    "elif results.is_file():\n",
    "    print(\"âš ï¸ Found file instead of directory\")\n",
    "    results.unlink()\n",
    "    print(\"ğŸ—‘ï¸ Removed file\")\n",
    "elif results.is_dir():\n",
    "    print(\"âœ… Results is already a real directory\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ Results doesn't exist yet\")\n",
    "\n",
    "# Create as real directory\n",
    "try:\n",
    "    results.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ… Created real directory: {results.resolve()}\")\n",
    "\n",
    "    # Verify\n",
    "    if results.is_dir() and not results.is_symlink():\n",
    "        print(\"\\nğŸ‰ SUCCESS! Results is now a proper directory\")\n",
    "        print(\"ğŸ“‚ You can now run the comprehensive test!\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Results exists but may have issues\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error creating directory: {e}\")\n",
    "    print(\"ğŸ’¡ Try: Runtime â†’ Restart runtime, then re-run Cell 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation and setup\n",
    "try:\n",
    "    from src.paths import get_project_root\n",
    "\n",
    "    print(\"âœ… Core modules imported successfully\")\n",
    "    print(f\"ğŸ“ Project root: {get_project_root()}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "\n",
    "# Check available models\n",
    "models_dir = Path(\"models\")\n",
    "if models_dir.exists():\n",
    "    print(\"\\nğŸ“‹ Available models:\")\n",
    "    for model in models_dir.iterdir():\n",
    "        if model.is_dir():\n",
    "            print(f\"  - {model.name}\")\n",
    "else:\n",
    "    print(\"âŒ Models directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data from Google Drive\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ“Š Setting up data from Google Drive...\")\n",
    "\n",
    "# Define paths\n",
    "drive_data_path = Path(\"/content/drive/MyDrive/Colab Notebooks/OAI_untracked\")\n",
    "local_data_path = Path(\"data\")\n",
    "\n",
    "# Check if Google Drive data exists\n",
    "if drive_data_path.exists():\n",
    "    print(f\"âœ… Found OAI data in Google Drive: {drive_data_path}\")\n",
    "\n",
    "    # Check data structure\n",
    "    oai_img_path = drive_data_path / \"data\" / \"oai\" / \"img\"\n",
    "    pretrained_path = drive_data_path / \"data\" / \"pretrained\"\n",
    "\n",
    "    if oai_img_path.exists():\n",
    "        img_count = len(list(oai_img_path.glob(\"*.png\")))\n",
    "        print(f\"ğŸ“¸ Found {img_count} OAI X-ray images\")\n",
    "    else:\n",
    "        print(\"âš ï¸ OAI images not found in expected location\")\n",
    "\n",
    "    if pretrained_path.exists():\n",
    "        model_files = list(pretrained_path.rglob(\"*.pt\")) + list(\n",
    "            pretrained_path.rglob(\"*.pth\")\n",
    "        )\n",
    "        print(f\"ğŸ¤– Found {len(model_files)} pretrained model files\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Pretrained models not found\")\n",
    "\n",
    "    # Check if data is already linked or setup\n",
    "    if local_data_path.is_symlink():\n",
    "        print(\"\\nâœ… Data already linked via symlink (from Cell 3)\")\n",
    "        print(f\"   {local_data_path} â†’ {os.readlink(local_data_path)}\")\n",
    "    elif (local_data_path / \"oai\").is_symlink():\n",
    "        print(\"\\nâœ… Data already linked via symlink (from Cell 3)\")\n",
    "        print(f\"   {local_data_path / 'oai'} â†’ {os.readlink(local_data_path / 'oai')}\")\n",
    "    else:\n",
    "        # Try to copy data for better performance\n",
    "        print(\"\\nğŸ“‹ Attempting to copy data from Google Drive to local storage...\")\n",
    "        print(\"   (This improves performance but requires disk space)\")\n",
    "\n",
    "        # Copy only if not already copied (check for a marker file)\n",
    "        marker_file = local_data_path / \".data_copied\"\n",
    "        if not marker_file.exists():\n",
    "            try:\n",
    "                # Create local data directory\n",
    "                local_data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Copy the entire data directory structure\n",
    "                source_data_path = drive_data_path / \"data\"\n",
    "                if source_data_path.exists():\n",
    "                    # Use rsync-like approach with os.walk for better control\n",
    "                    print(\"   Copying files... (this may take a few minutes)\")\n",
    "                    file_count = 0\n",
    "                    for root, _dirs, files in os.walk(source_data_path):\n",
    "                        rel_path = Path(root).relative_to(source_data_path)\n",
    "                        dest_dir = local_data_path / rel_path\n",
    "                        dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                        for file in files:\n",
    "                            src_file = Path(root) / file\n",
    "                            dst_file = dest_dir / file\n",
    "                            if not dst_file.exists():\n",
    "                                shutil.copy2(src_file, dst_file)\n",
    "                                file_count += 1\n",
    "                                if file_count % 100 == 0:\n",
    "                                    print(f\"   Copied {file_count} files...\")\n",
    "\n",
    "                    print(f\"âœ… Data copied successfully ({file_count} files)\")\n",
    "                    marker_file.touch()\n",
    "                else:\n",
    "                    print(\"âŒ Data directory not found in expected structure\")\n",
    "                    print(\"ğŸ’¡ Please check your Google Drive structure\")\n",
    "\n",
    "            except Exception as e:\n",
    "                error_msg = str(e)[:200]  # Truncate to prevent massive output\n",
    "                print(f\"âŒ Error copying data: {error_msg}...\")\n",
    "                print(\"ğŸ’¡ Falling back to symlink approach...\")\n",
    "                # Fallback to symlink\n",
    "                try:\n",
    "                    if local_data_path.exists() and not local_data_path.is_symlink():\n",
    "                        shutil.rmtree(local_data_path)\n",
    "                    if not local_data_path.exists():\n",
    "                        local_data_path.symlink_to(drive_data_path / \"data\")\n",
    "                        print(\"âœ… Created symlink instead\")\n",
    "                except Exception as link_error:\n",
    "                    print(f\"âŒ Symlink also failed: {link_error}\")\n",
    "        else:\n",
    "            print(\"âœ… Data already copied (skipping)\")\n",
    "\n",
    "    # Verify data structure\n",
    "    print(\"\\nğŸ“‹ Verifying data structure...\")\n",
    "    oai_local_path = local_data_path / \"oai\"\n",
    "    pretrained_local_path = local_data_path / \"pretrained\"\n",
    "\n",
    "    # Check OAI data\n",
    "    if oai_local_path.exists():\n",
    "        img_path = oai_local_path / \"img\"\n",
    "        if img_path.exists():\n",
    "            img_count = len(list(img_path.glob(\"*.png\")))\n",
    "            print(f\"  âœ… oai/img/ ({img_count} PNG files)\")\n",
    "        else:\n",
    "            print(\"  âŒ oai/img/ (missing)\")\n",
    "    else:\n",
    "        print(\"  âŒ oai/ directory (missing)\")\n",
    "\n",
    "    # Check pretrained models\n",
    "    if pretrained_local_path.exists():\n",
    "        model_files = list(pretrained_local_path.rglob(\"*.pt\")) + list(\n",
    "            pretrained_local_path.rglob(\"*.pth\")\n",
    "        )\n",
    "        print(f\"  âœ… pretrained/ ({len(model_files)} model files)\")\n",
    "\n",
    "        # Check specific model directories\n",
    "        for model_dir in [\"aot-gan\", \"ict\", \"repaint\"]:\n",
    "            model_path = pretrained_local_path / model_dir\n",
    "            if model_path.exists():\n",
    "                model_count = len(\n",
    "                    list(model_path.rglob(\"*.pt\")) + list(model_path.rglob(\"*.pth\"))\n",
    "                )\n",
    "                print(f\"    âœ… {model_dir}/ ({model_count} files)\")\n",
    "            else:\n",
    "                print(f\"    âŒ {model_dir}/ (missing)\")\n",
    "    else:\n",
    "        print(\"  âŒ pretrained/ directory (missing)\")\n",
    "\n",
    "    # Check for generated directories (will be created by split.py)\n",
    "    generated_dirs = [\"train\", \"valid\", \"test\"]\n",
    "    for dir_name in generated_dirs:\n",
    "        dir_path = oai_local_path / dir_name\n",
    "        if dir_path.exists():\n",
    "            file_count = len(list(dir_path.rglob(\"*\")))\n",
    "            print(f\"  âœ… oai/{dir_name}/ ({file_count} files) - Generated\")\n",
    "        else:\n",
    "            print(f\"  â³ oai/{dir_name}/ (will be generated by split.py)\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ OAI data not found in Google Drive\")\n",
    "    print(\"ğŸ’¡ Please ensure your data is uploaded to:\")\n",
    "    print(\"   /content/drive/MyDrive/Colab Notebooks/OAI_untracked\")\n",
    "    print(\"\\nğŸ“¤ Expected structure:\")\n",
    "    print(\"   OAI_untracked/\")\n",
    "    print(\"   â”œâ”€â”€ data/\")\n",
    "    print(\"   â”‚   â”œâ”€â”€ oai/\")\n",
    "    print(\"   â”‚   â”‚   â””â”€â”€ img/          # 539 PNG files\")\n",
    "    print(\"   â”‚   â””â”€â”€ pretrained/       # Model files\")\n",
    "    print(\"   â””â”€â”€ README.md\")\n",
    "    print(\"\\nğŸ“¤ To upload data:\")\n",
    "    print(\"1. Go to Google Drive\")\n",
    "    print(\"2. Navigate to 'Colab Notebooks' folder\")\n",
    "    print(\"3. Create 'OAI_untracked' folder\")\n",
    "    print(\"4. Upload your OAI dataset files there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Update Repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ GENERATE DATASET SPLITS (Required before testing!)\n",
    "# This creates PERFECTLY BALANCED train/valid/test splits using ALL 539 images\n",
    "# â€¢ 80% train (431 images), 10% validation (53 images), 10% test (55 images)\n",
    "# â€¢ Equal low/high BMD representation in each split\n",
    "# â€¢ Mutually exclusive (no image overlap between splits)\n",
    "# â€¢ Also creates subset_4 (4 test images) for quick testing\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ”„ GENERATING PERFECTLY BALANCED DATASET SPLITS\")\n",
    "print(\"Using ALL 539 images with 80/10/10 split\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if splits already exist\n",
    "subset_4_path = Path(\"data/oai/test/img/subset_4\")\n",
    "if subset_4_path.exists() and any(subset_4_path.glob(\"*.png\")):\n",
    "    file_count = len(list(subset_4_path.glob(\"*.png\")))\n",
    "    print(\"âœ… Splits already exist!\")\n",
    "    print(f\"âœ… Found {file_count} files in subset_4\")\n",
    "    print(\"\\nğŸ’¡ Skipping split generation - already done\")\n",
    "else:\n",
    "    print(\"âš ï¸  Splits not found - generating now...\")\n",
    "    print(\"This will create:\")\n",
    "    print(\"  â€¢ Train/valid/test splits\")\n",
    "    print(\"  â€¢ Random masks\")\n",
    "    print(\"  â€¢ Edge maps\")\n",
    "    print(\"  â€¢ Inverted masks\")\n",
    "    print(\"  â€¢ subset_4 evaluation set (4 images)\")\n",
    "\n",
    "    # Run split.py\n",
    "    result = subprocess.run(\n",
    "        [\"python\", \"split.py\"],\n",
    "        check=False,\n",
    "        cwd=\"data/oai\",\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=300,\n",
    "    )\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ… PERFECTLY BALANCED dataset splits generated successfully!\")\n",
    "        print(\"\\nğŸ“Š Split Summary:\")\n",
    "\n",
    "        # Count actual files in each split\n",
    "        train_count = (\n",
    "            len(list(Path(\"data/oai/train/img\").glob(\"*.png\")))\n",
    "            if Path(\"data/oai/train/img\").exists()\n",
    "            else 0\n",
    "        )\n",
    "        val_count = (\n",
    "            len(list(Path(\"data/oai/valid/img\").glob(\"*.png\")))\n",
    "            if Path(\"data/oai/valid/img\").exists()\n",
    "            else 0\n",
    "        )\n",
    "        test_count = (\n",
    "            len(list(Path(\"data/oai/test/img\").glob(\"*.png\")))\n",
    "            if Path(\"data/oai/test/img\").exists()\n",
    "            else 0\n",
    "        )\n",
    "        total_count = train_count + val_count + test_count\n",
    "\n",
    "        print(\n",
    "            f\"  ğŸ“ Train: {train_count} images ({train_count / total_count * 100:.1f}%)\"\n",
    "        )\n",
    "        print(f\"  ğŸ“ Valid: {val_count} images ({val_count / total_count * 100:.1f}%)\")\n",
    "        print(\n",
    "            f\"  ğŸ“ Test:  {test_count} images ({test_count / total_count * 100:.1f}%)\"\n",
    "        )\n",
    "        print(f\"  ğŸ“ TOTAL: {total_count} images\")\n",
    "\n",
    "        # Verify subset_4 was created\n",
    "        if subset_4_path.exists():\n",
    "            img_count = len(list(subset_4_path.glob(\"*.png\")))\n",
    "            print(\n",
    "                f\"\\nâœ… subset_4 created with {img_count} images (2 low BMD + 2 high BMD)\"\n",
    "            )\n",
    "\n",
    "            # Verify all required directories\n",
    "            required_dirs = [\n",
    "                \"data/oai/test/img/subset_4\",\n",
    "                \"data/oai/test/mask/subset_4\",\n",
    "                \"data/oai/test/edge/subset_4\",\n",
    "                \"data/oai/test/mask_inv/subset_4\",\n",
    "            ]\n",
    "\n",
    "            print(\"\\nğŸ“‹ Verification:\")\n",
    "            for dir_path in required_dirs:\n",
    "                p = Path(dir_path)\n",
    "                if p.exists():\n",
    "                    count = len(list(p.glob(\"*.png\")))\n",
    "                    print(\n",
    "                        f\"  âœ… {dir_path.split('/')[-2]}/{dir_path.split('/')[-1]}/: {count} files\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"  âŒ {dir_path}: missing\")\n",
    "\n",
    "            print(\"\\nğŸ‰ Ready for training, testing, and evaluation!\")\n",
    "        else:\n",
    "            print(\"âš ï¸ subset_4 not created - check output above\")\n",
    "            if result.stdout:\n",
    "                print(f\"Output: {result.stdout}\")\n",
    "    else:\n",
    "        print(f\"âŒ Split failed with exit code {result.returncode}\")\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "        print(\"\\nğŸ’¡ Try running manually:\")\n",
    "        print(\"  !cd data/oai && python split.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Training, Testing & Evaluation\n",
    "\n",
    "Now that you have the perfectly balanced dataset splits, you can:\n",
    "- **Test** pretrained models on the test set\n",
    "- **Train** new models on the full 431-image training set\n",
    "- **Evaluate** model performance with comprehensive metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ PIPELINE RUNNER SETUP\n",
    "# Import the pipeline runner functions\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"scripts\")\n",
    "\n",
    "try:\n",
    "    from colab_comprehensive_test import ModelTester\n",
    "    from colab_pipeline import run_full_pipeline, run_phase\n",
    "\n",
    "    print(\"âœ… Pipeline runner imported successfully!\")\n",
    "    print(\"\")\n",
    "    print(\"ğŸ¯ Available functions:\")\n",
    "    print(\"\")\n",
    "    print(\"ğŸ“Š COMPREHENSIVE TESTING (Recommended):\")\n",
    "    print(\"  - ModelTester().run_comprehensive_test() - Test ALL 9 model variants\")\n",
    "    print(\"     â€¢ AOT-GAN: CelebA-HQ, Places2, OAI\")\n",
    "    print(\"     â€¢ ICT: FFHQ, ImageNet, Places2_Nature, OAI\")\n",
    "    print(\"     â€¢ RePaint: CelebA-HQ, ImageNet, Places2\")\n",
    "    print(\"\")\n",
    "    print(\"ğŸ”„ PHASED PIPELINE (For training):\")\n",
    "    print(\"  - run_full_pipeline() - Run all 5 phases\")\n",
    "    print(\"  - run_phase(1) - Quick verification\")\n",
    "    print(\"  - run_phase(2) - AOT-GAN training\")\n",
    "    print(\"  - run_phase(3) - ICT training\")\n",
    "    print(\"  - run_phase(4) - RePaint inference\")\n",
    "    print(\"  - run_phase(5) - Evaluation\")\n",
    "    print(\"\")\n",
    "    print(\"ğŸ’¡ Ready to use! Go to the next cell to run commands.\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure you've run the repository setup cell first\")\n",
    "    print(\"ğŸ’¡ The scripts should be in the scripts/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Quick Workflow: Train, Test & Evaluate on Balanced Dataset\n",
    "\n",
    "The cells below provide different workflows based on your needs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ OPTION 1: Quick Test on Balanced Dataset (Recommended First Step)\n",
    "# Tests all 9 pretrained model variants on the subset_4 (4 balanced test images)\n",
    "# â±ï¸ Time: ~30-60 minutes\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¯ QUICK TEST: All Models on Balanced subset_4\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing 9 model variants on 4 balanced images:\")\n",
    "print(\"  â€¢ 2 low BMD images\")\n",
    "print(\"  â€¢ 2 high BMD images\")\n",
    "print(\"\")\n",
    "\n",
    "tester = ModelTester(timeout_per_model=600, verbose=True)\n",
    "results = tester.run_comprehensive_test(models=[\"all\"])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ‰ QUICK TEST COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"âœ… Successful: {results['summary']['successful']}\")\n",
    "print(f\"âŒ Failed: {results['summary']['failed']}\")\n",
    "print(f\"â­ï¸ Skipped: {results['summary']['skipped']}\")\n",
    "print(\"\")\n",
    "print(\"ğŸ“ Check results/ directory for output images\")\n",
    "print(\"ğŸ“Š Check results/comprehensive_test_results.json for detailed results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ OPTION 2: Train on Full Balanced Dataset & Evaluate\n",
    "# Trains models on the full 431-image training set with balanced BMD representation\n",
    "# â±ï¸ Time: 6-8 hours (runs all training phases)\n",
    "#\n",
    "# This will:\n",
    "# 1. Train AOT-GAN on 431 balanced training images\n",
    "# 2. Train ICT (Transformer) on 431 balanced training images\n",
    "# 3. Run RePaint inference on test set\n",
    "# 4. Evaluate all models on the 55-image balanced test set\n",
    "# 5. Generate comprehensive metrics and visualizations\n",
    "\n",
    "# Uncomment to run full training pipeline\n",
    "# print(\"=\" * 60)\n",
    "# print(\"ğŸ“ FULL TRAINING PIPELINE ON BALANCED DATASET\")\n",
    "# print(\"=\" * 60)\n",
    "# print(\"Training on:\")\n",
    "# print(\"  â€¢ 431 images (215 low BMD + 216 high BMD)\")\n",
    "# print(\"  â€¢ 53 validation images (26 low BMD + 27 high BMD)\")\n",
    "# print(\"  â€¢ 55 test images (28 low BMD + 27 high BMD)\")\n",
    "# print(\"\")\n",
    "#\n",
    "# run_full_pipeline(timeout_hours=8)\n",
    "\n",
    "print(\"ğŸ’¡ To run full training pipeline:\")\n",
    "print(\"   1. Uncomment the code above\")\n",
    "print(\"   2. Run this cell\")\n",
    "print(\"   3. Wait 6-8 hours for training to complete\")\n",
    "print(\"\")\n",
    "print(\"ğŸ“Š Benefits of the new balanced split:\")\n",
    "print(\"   â€¢ 2x more training data (431 vs ~216)\")\n",
    "print(\"   â€¢ Equal representation of low/high BMD cases\")\n",
    "print(\"   â€¢ Better model generalization\")\n",
    "print(\"   â€¢ More reliable evaluation metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” OPTION 3: Test Specific Model on Full Balanced Test Set\n",
    "# Test a single model on all 55 balanced test images (instead of just subset_4)\n",
    "# â±ï¸ Time: ~5-15 minutes per model\n",
    "\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def test_model_on_full_test_set(model_name, config_path):\n",
    "    \"\"\"Test a specific model on the full 55-image balanced test set.\"\"\"\n",
    "    print(f\"ğŸ§ª Testing {model_name} on full balanced test set (55 images)...\")\n",
    "    print(f\"   Using config: {config_path}\")\n",
    "\n",
    "    # Run the appropriate test script based on model\n",
    "    if \"aot-gan\" in model_name.lower():\n",
    "        cmd = [\n",
    "            \"python\",\n",
    "            \"scripts/test.py\",\n",
    "            \"--model\",\n",
    "            \"aot-gan\",\n",
    "            \"--config\",\n",
    "            config_path,\n",
    "        ]\n",
    "    elif \"ict\" in model_name.lower():\n",
    "        cmd = [\"python\", \"scripts/test.py\", \"--model\", \"ict\", \"--config\", config_path]\n",
    "    elif \"repaint\" in model_name.lower():\n",
    "        cmd = [\n",
    "            \"python\",\n",
    "            \"scripts/test.py\",\n",
    "            \"--model\",\n",
    "            \"repaint\",\n",
    "            \"--config\",\n",
    "            config_path,\n",
    "        ]\n",
    "    else:\n",
    "        print(f\"âŒ Unknown model: {model_name}\")\n",
    "        return\n",
    "\n",
    "    result = subprocess.run(\n",
    "        cmd, check=False, capture_output=True, text=True, timeout=1800\n",
    "    )\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        print(f\"âœ… {model_name} testing completed!\")\n",
    "        print(f\"ğŸ“ Results saved to results/{model_name}/\")\n",
    "    else:\n",
    "        print(f\"âŒ {model_name} testing failed\")\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# test_model_on_full_test_set(\"AOT-GAN-OAI\", \"configs/oai_config.yml\")\n",
    "# test_model_on_full_test_set(\"ICT-OAI\", \"models/ict/Guided_Upsample/subset_4_config.yml\")\n",
    "\n",
    "print(\"ğŸ’¡ To test a specific model on the full balanced test set:\")\n",
    "print(\"   1. Uncomment one of the examples above\")\n",
    "print(\"   2. Adjust the model name and config path as needed\")\n",
    "print(\"   3. Run this cell\")\n",
    "print(\"\")\n",
    "print(\"ğŸ“Š Full test set: 55 images (28 low BMD + 27 high BMD)\")\n",
    "print(\"   vs. subset_4: 4 images (2 low BMD + 2 high BMD)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ QUICK START - Test ALL Model Variants (RECOMMENDED)\n",
    "# This tests all 9 pretrained models on 4 OAI X-ray images\n",
    "# Perfect for quick validation and comparison!\n",
    "\n",
    "tester = ModelTester(timeout_per_model=600, verbose=True)\n",
    "results = tester.run_comprehensive_test(models=[\"all\"])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ‰ COMPREHENSIVE TEST COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"âœ… Successful: {results['summary']['successful']}\")\n",
    "print(f\"âŒ Failed: {results['summary']['failed']}\")\n",
    "print(f\"â­ï¸ Skipped: {results['summary']['skipped']}\")\n",
    "print(\"\")\n",
    "print(\"ğŸ“ Check results/ directory for output images\")\n",
    "print(\"ğŸ“Š Check results/comprehensive_test_results.json for detailed results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ ALTERNATIVE - Test Specific Model Types\n",
    "# If you only want to test specific models:\n",
    "\n",
    "# Test only AOT-GAN variants\n",
    "# tester = ModelTester(timeout_per_model=600)\n",
    "# results = tester.run_comprehensive_test(models=[\"aot-gan\"])\n",
    "\n",
    "# Test only ICT variants\n",
    "# tester = ModelTester(timeout_per_model=600)\n",
    "# results = tester.run_comprehensive_test(models=[\"ict\"])\n",
    "\n",
    "# Test only RePaint variants\n",
    "# tester = ModelTester(timeout_per_model=600)\n",
    "# results = tester.run_comprehensive_test(models=[\"repaint\"])\n",
    "\n",
    "# Test multiple specific models\n",
    "# tester = ModelTester(timeout_per_model=600)\n",
    "# results = tester.run_comprehensive_test(models=[\"aot-gan\", \"repaint\"])\n",
    "\n",
    "print(\"ğŸ’¡ Uncomment the code above to test specific model types\")\n",
    "print(\"ğŸ’¡ Or run the previous cell to test all models at once\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Training Pipeline (Optional)\n",
    "\n",
    "If you want to train new models on OAI data instead of just testing pretrained models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ TRAINING PIPELINE - Train models on OAI data\n",
    "# Uncomment to run the full training pipeline (6-8 hours)\n",
    "\n",
    "# Run complete pipeline (all phases)\n",
    "# run_full_pipeline(timeout_hours=8)\n",
    "\n",
    "# Or run individual phases:\n",
    "# run_phase(1)  # Quick verification (5 min)\n",
    "# run_phase(2)  # AOT-GAN training (2-4 hours)\n",
    "# run_phase(3)  # ICT training (1-3 hours)\n",
    "# run_phase(4)  # RePaint inference (30 min)\n",
    "# run_phase(5)  # Evaluation (15 min)\n",
    "\n",
    "print(\"ğŸ“‹ Training Pipeline Options:\")\n",
    "print(\"\")\n",
    "print(\"âš¡ Quick verification only:\")\n",
    "print(\"   run_phase(1)\")\n",
    "print(\"\")\n",
    "print(\"ğŸ”§ Train specific model:\")\n",
    "print(\"   run_phase(2)  # AOT-GAN only\")\n",
    "print(\"   run_phase(3)  # ICT only\")\n",
    "print(\"   run_phase(4)  # RePaint inference only\")\n",
    "print(\"\")\n",
    "print(\"ğŸš€ Train all models:\")\n",
    "print(\"   run_full_pipeline(timeout_hours=8)\")\n",
    "print(\"\")\n",
    "print(\"âš ï¸  Warning: Training takes 6-8 hours total\")\n",
    "print(\"ğŸ’¡ Tip: Test with run_phase(1) first to verify setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ Comparison Strips Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¨ GENERATE COMPARISON STRIPS\n",
    "# Creates horizontal comparison images: GT, GT+Mask, and all model outputs\n",
    "# Perfect for visual assessment and thesis inclusion!\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"scripts\")\n",
    "\n",
    "try:\n",
    "    from generate_comparison_strips import main as generate_strips\n",
    "\n",
    "    print(\"ğŸ¨ Generating visual comparison strips...\")\n",
    "    print(\"This creates horizontal strips showing all model outputs side-by-side\")\n",
    "    print(\"\")\n",
    "\n",
    "    strip_paths = generate_strips()\n",
    "\n",
    "    if strip_paths:\n",
    "        print(f\"\\nâœ… Generated {len(strip_paths)} comparison strips!\")\n",
    "        print(\"ğŸ“ Location: results/comparison_strips/\")\n",
    "        print(\"\")\n",
    "        print(\"ğŸ“¸ Files created:\")\n",
    "        for path in strip_paths:\n",
    "            print(f\"  - {path.name}\")\n",
    "        print(\"  - all_comparisons_summary.png (all strips stacked)\")\n",
    "        print(\"\")\n",
    "        print(\"ğŸ’¡ Each strip shows:\")\n",
    "        print(\"   GT â†’ GT+Mask â†’ AOT-GAN variants â†’ ICT variants â†’ RePaint variants\")\n",
    "    else:\n",
    "        print(\"âš ï¸  No strips generated - check that comprehensive test completed\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure you've run the setup cells first\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error generating strips: {e}\")\n",
    "    print(\"ğŸ’¡ Ensure comprehensive test completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Results Visualization and Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Visualize Results\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Check if results exist\n",
    "results_json = Path(\"results/comprehensive_test_results.json\")\n",
    "if results_json.exists():\n",
    "    with results_json.open() as f:\n",
    "        test_results = json.load(f)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ“Š TEST RESULTS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Timestamp: {test_results['timestamp']}\")\n",
    "    print(f\"Duration: {test_results['duration']}\")\n",
    "    print(f\"Total tests: {test_results['summary']['total']}\")\n",
    "    print(f\"Successful: {test_results['summary']['successful']}\")\n",
    "    print(f\"Failed: {test_results['summary']['failed']}\")\n",
    "    print(f\"Skipped: {test_results['summary']['skipped']}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Show which models passed\n",
    "    print(\"âœ… SUCCESSFUL MODELS:\")\n",
    "    for result in test_results[\"results\"]:\n",
    "        if result[\"success\"]:\n",
    "            print(f\"  â€¢ {result['model']} ({result['elapsed']:.1f}s)\")\n",
    "\n",
    "    # Show which models were skipped/failed\n",
    "    if test_results[\"summary\"][\"skipped\"] > 0:\n",
    "        print(\"\")\n",
    "        print(\"â­ï¸ SKIPPED MODELS:\")\n",
    "        for result in test_results[\"results\"]:\n",
    "            if \"reason\" in result:\n",
    "                print(f\"  â€¢ {result['model']} ({result['reason']})\")\n",
    "\n",
    "    if test_results[\"summary\"][\"failed\"] > 0:\n",
    "        print(\"\")\n",
    "        print(\"âŒ FAILED MODELS:\")\n",
    "        for result in test_results[\"results\"]:\n",
    "            if not result[\"success\"] and \"reason\" not in result:\n",
    "                print(f\"  â€¢ {result['model']}\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸  No test results found. Run the comprehensive test first!\")\n",
    "    print(\"ğŸ’¡ Execute the 'QUICK START' cell above to generate results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¸ Display Sample Results (if available)\n",
    "# Show inpainted images from successful tests\n",
    "\n",
    "results_base = Path(\"results\")\n",
    "\n",
    "# Find the first successful result directory\n",
    "sample_dirs = []\n",
    "for model_type in [\"AOT-GAN\", \"ICT\", \"RePaint\"]:\n",
    "    model_path = results_base / model_type\n",
    "    if model_path.exists():\n",
    "        for variant in model_path.iterdir():\n",
    "            subset_4_path = variant / \"subset_4\"\n",
    "            if subset_4_path.exists():\n",
    "                # Check for images\n",
    "                image_files = list(subset_4_path.rglob(\"*.png\"))\n",
    "                if image_files:\n",
    "                    sample_dirs.append((f\"{model_type} {variant.name}\", subset_4_path))\n",
    "\n",
    "if sample_dirs:\n",
    "    print(f\"ğŸ“¸ Found results from {len(sample_dirs)} model variants\")\n",
    "    print(\"\")\n",
    "    print(\"Available results:\")\n",
    "    for i, (name, path) in enumerate(sample_dirs):\n",
    "        image_count = len(list(path.rglob(\"*.png\")))\n",
    "        print(f\"  {i + 1}. {name} ({image_count} images)\")\n",
    "\n",
    "    # Display sample from first available model\n",
    "    if len(sample_dirs) > 0:\n",
    "        model_name, sample_path = sample_dirs[0]\n",
    "        sample_images = sorted(sample_path.rglob(\"*.png\"))[:4]\n",
    "\n",
    "        if sample_images:\n",
    "            print(f\"\\nğŸ–¼ï¸  Displaying samples from: {model_name}\")\n",
    "            print(f\"ğŸ“ Path: {sample_path}\")\n",
    "\n",
    "            # Create grid\n",
    "            fig, axes = plt.subplots(1, min(4, len(sample_images)), figsize=(15, 4))\n",
    "            if len(sample_images) == 1:\n",
    "                axes = [axes]\n",
    "\n",
    "            for idx, img_path in enumerate(sample_images[:4]):\n",
    "                img = Image.open(img_path)\n",
    "                if idx < len(axes):\n",
    "                    axes[idx].imshow(img, cmap=\"gray\")\n",
    "                    axes[idx].set_title(img_path.name)\n",
    "                    axes[idx].axis(\"off\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"ğŸ’¡ To view more results, explore the results/ directory\")\n",
    "else:\n",
    "    print(\"âš ï¸  No result images found yet\")\n",
    "    print(\"ğŸ’¡ Run the comprehensive test first to generate results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¾ Download Results\n",
    "# Package and download all results as a ZIP file\n",
    "\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Check if we're in Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    results_dir = Path(\"results\")\n",
    "\n",
    "    if results_dir.exists() and any(results_dir.iterdir()):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        zip_filename = f\"oai_inpainting_results_{timestamp}.zip\"\n",
    "\n",
    "        print(f\"ğŸ“¦ Creating results archive: {zip_filename}\")\n",
    "        print(\"This may take a few minutes...\")\n",
    "\n",
    "        # Create ZIP file\n",
    "        with zipfile.ZipFile(zip_filename, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for file_path in results_dir.rglob(\"*\"):\n",
    "                if file_path.is_file():\n",
    "                    arcname = file_path.relative_to(results_dir.parent)\n",
    "                    zipf.write(file_path, arcname)\n",
    "                    if file_path.suffix in [\".png\", \".jpg\", \".json\", \".txt\"]:\n",
    "                        print(f\"  Added: {arcname}\")\n",
    "\n",
    "        print(f\"âœ… Archive created: {zip_filename}\")\n",
    "        print(f\"ğŸ“¦ Size: {Path(zip_filename).stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "        print(\"\")\n",
    "        print(\"â¬‡ï¸  Downloading...\")\n",
    "\n",
    "        # Download the file\n",
    "        files.download(zip_filename)\n",
    "\n",
    "        print(\"âœ… Download initiated!\")\n",
    "        print(\"ğŸ’¡ Check your browser's download folder\")\n",
    "    else:\n",
    "        print(\"âš ï¸  No results found to download\")\n",
    "        print(\"ğŸ’¡ Run the comprehensive test first to generate results\")\n",
    "else:\n",
    "    print(\"âš ï¸  Not running in Google Colab\")\n",
    "    print(\"ğŸ’¡ This cell is designed for Colab environment\")\n",
    "    print(\"ğŸ“ Results are available locally in the results/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update repository to latest version\n",
    "print(\"ğŸ”„ Updating repository...\")\n",
    "\n",
    "try:\n",
    "    # Fetch latest changes\n",
    "    subprocess.run([\"git\", \"fetch\"], check=True)\n",
    "\n",
    "    # Check for updates\n",
    "    result = subprocess.run(\n",
    "        [\"git\", \"status\", \"-uno\"], check=False, capture_output=True, text=True\n",
    "    )\n",
    "    print(\"ğŸ“‹ Repository status:\")\n",
    "    print(result.stdout)\n",
    "\n",
    "    # Pull latest changes\n",
    "    subprocess.run([\"git\", \"pull\"], check=True)\n",
    "    print(\"âœ… Repository updated to latest version\")\n",
    "\n",
    "    # Reinstall dependencies if needed\n",
    "    print(\"ğŸ“¦ Reinstalling dependencies...\")\n",
    "    subprocess.run([\"pip\", \"install\", \"-e\", \".[dev,ml]\"], check=True)\n",
    "    print(\"âœ… Dependencies updated\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Update failed: {e}\")\n",
    "    print(\"ğŸ’¡ You may need to restart the runtime and re-run the setup cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting and Tips\n",
    "print(\"ğŸ”§ Troubleshooting and Tips\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nğŸ“‹ Common Issues and Solutions:\")\n",
    "print(\"1. âŒ 'run_phase' is not defined\")\n",
    "print(\"   ğŸ’¡ Solution: Run the 'Pipeline Runner Setup' cell first\")\n",
    "print(\"\")\n",
    "print(\"2. âŒ Import errors\")\n",
    "print(\"   ğŸ’¡ Solution: Restart runtime and re-run all setup cells\")\n",
    "print(\"\")\n",
    "print(\"3. âŒ Data not found\")\n",
    "print(\"   ğŸ’¡ Solution: Check Google Drive mounting and data structure\")\n",
    "print(\"\")\n",
    "print(\"4. âŒ GPU not available\")\n",
    "print(\"   ğŸ’¡ Solution: Enable GPU in Runtime â†’ Change runtime type\")\n",
    "print(\"\")\n",
    "print(\"5. âŒ Out of memory\")\n",
    "print(\"   ğŸ’¡ Solution: Reduce batch size or restart runtime\")\n",
    "\n",
    "print(\"\\nğŸš€ Quick Commands:\")\n",
    "print(\"â€¢ Check GPU: !nvidia-smi\")\n",
    "print(\"â€¢ Check directory: !pwd\")\n",
    "print(\"â€¢ List files: !ls -la\")\n",
    "print(\"â€¢ Check Python: !python --version\")\n",
    "print(\"â€¢ Check PyTorch: !python -c 'import torch; print(torch.__version__)'\")\n",
    "\n",
    "print(\"\\nğŸ“ Getting Help:\")\n",
    "print(\"â€¢ Check the README.md for detailed instructions\")\n",
    "print(\"â€¢ Review error messages carefully\")\n",
    "print(\"â€¢ Restart runtime if issues persist\")\n",
    "print(\"â€¢ Ensure all setup cells have run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
