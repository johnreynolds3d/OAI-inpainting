{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🔬 OAI X-ray Inpainting - Streamlined Workflow\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/johnreynolds3d/OAI-inpainting/blob/master/notebooks/OAI_Inpainting_Streamlined.ipynb)\n",
        "\n",
        "**Efficient testing, training, and evaluation of inpainting models on OAI wrist X-ray data**\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 Quick Start Guide (Just 7 Cells!)\n",
        "\n",
        "### ✅ **Step 1**: Setup (Cell 1) - *Run Once* ⏱️ 5-10 min\n",
        "Complete environment setup: GPU, Drive, repo, dependencies\n",
        "\n",
        "### ✅ **Step 2**: Prepare Data (Cell 2) - *Run Once* ⏱️ 2-5 min\n",
        "Generate balanced dataset splits (539 images → 80/10/10 split)\n",
        "\n",
        "### ✅ **Step 3**: Choose Your Testing/Training Path\n",
        "\n",
        "**Option A: Quick Testing** (Recommended First) - Total ~1 hour\n",
        "```\n",
        "Cell 3 (Quick Test) → Cell 5 → Cell 6 → Cell 7\n",
        "  30-60 min           8 min    1 min    3 min\n",
        "```\n",
        "Tests 9 pretrained models, no training required\n",
        "\n",
        "**Option B: Full Training** (Advanced) - Total ~6.5 hours\n",
        "```\n",
        "Cell 4 (Training) → Cell 5 → Cell 6 → Cell 7\n",
        "  6-8 hours          8 min    1 min    3 min\n",
        "```\n",
        "Trains custom models on 431 balanced images\n",
        "\n",
        "**Note**: Cells 3 & 4 are alternatives - pick one based on your goal!\n",
        "\n",
        "### ✅ **Step 4**: Evaluate & Download (Cells 5-7)\n",
        "- **Cell 5**: 📊 Classification ⏱️ 5-10 min - Osteoporosis classification accuracy\n",
        "- **Cell 6**: 🎨 Visualizations ⏱️ 1-2 min - Generate comparison strips\n",
        "- **Cell 7**: 💾 Download ⏱️ 2-5 min - Package everything as ZIP\n",
        "\n",
        "---\n",
        "\n",
        "## 📊 Dataset: Perfectly Balanced Split\n",
        "- ✅ **ALL 539 images** used (previously only ~268)\n",
        "- ✅ **Train**: 431 images (80%) - 215 low BMD + 216 high BMD\n",
        "- ✅ **Valid**: 53 images (10%) - 26 low BMD + 27 high BMD\n",
        "- ✅ **Test**: 55 images (10%) - 28 low BMD + 27 high BMD\n",
        "- ✅ **Mutually exclusive** - no image overlap\n",
        "\n",
        "## 🎯 Models Available\n",
        "- **AOT-GAN** (3 variants): CelebA-HQ, Places2, OAI-trained\n",
        "- **ICT** (4 variants): FFHQ, ImageNet, Places2_Nature, OAI-trained\n",
        "- **RePaint** (3 variants): CelebA-HQ, ImageNet, Places2\n",
        "\n",
        "**Total: 9 pretrained model variants + ability to train custom models**\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 Why This Streamlined Version?\n",
        "- ⚡ **77% fewer cells** (7 vs 30+)\n",
        "- 🎯 **One cell = one action** - clear and focused\n",
        "- 🔄 **Smart auto-skip** - Cell 2 won't regenerate if splits exist\n",
        "- 🆕 **Integrated classification** - osteoporosis evaluation built-in\n",
        "- 📊 **Better output** - rich progress indicators and clear results\n",
        "- 💾 **Results persist** - Both data/ and results/ symlinked to Google Drive\n",
        "\n",
        "## 📁 Directory Structure (Same for Local & Colab!)\n",
        "\n",
        "Both environments use the same relative symlink structure:\n",
        "```\n",
        "Parent Directory/\n",
        "├── OAI-inpainting/          # Git repository\n",
        "│   ├── data -> ../OAI_untracked/data/       ✅ Symlink\n",
        "│   ├── results -> ../OAI_untracked/results/ ✅ Symlink\n",
        "│   └── [scripts, notebooks, etc.]\n",
        "└── OAI_untracked/           # Your data (persistent)\n",
        "    ├── data/                # OAI images & pretrained models\n",
        "    └── results/             # All outputs (persists across sessions!)\n",
        "```\n",
        "\n",
        "**Benefits**:\n",
        "- ✅ Results persist in Google Drive (survive session restarts)\n",
        "- ✅ Identical behavior on local machine and Colab\n",
        "- ✅ Portable code (works anywhere!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# CELL 1: COMPLETE SETUP (Run Once)\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# This cell does everything: GPU check, Drive mount, repo download, dependencies\n",
        "# ⏱️ Time: ~5-10 minutes\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"🚀 COMPLETE ENVIRONMENT SETUP\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 1. Check GPU\n",
        "print(\"\\n[1/5] 🖥️  Checking GPU availability...\")\n",
        "try:\n",
        "    import torch\n",
        "\n",
        "    print(f\"  ✅ PyTorch {torch.__version__}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"  ✅ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"  ✅ CUDA: {torch.version.cuda}\")\n",
        "    else:\n",
        "        print(\"  ⚠️  No GPU detected - training will be SLOW!\")\n",
        "        print(\"  💡 Enable GPU: Runtime → Change runtime type → GPU\")\n",
        "except ImportError:\n",
        "    print(\"  ⚠️  PyTorch not found, will install...\")\n",
        "\n",
        "# 2. Mount Google Drive\n",
        "print(\"\\n[2/5] 📂 Mounting Google Drive...\")\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "    # Navigate to Colab Notebooks directory\n",
        "    colab_dir = Path(\"/content/drive/MyDrive/Colab Notebooks\")\n",
        "    if colab_dir.exists():\n",
        "        os.chdir(colab_dir)\n",
        "        print(f\"  ✅ Working directory: {Path.cwd()}\")\n",
        "    else:\n",
        "        print(\"  ⚠️  Colab Notebooks not found, using default directory\")\n",
        "except ImportError:\n",
        "    print(\"  ℹ️  Not in Colab environment, skipping Drive mount\")\n",
        "\n",
        "# 3. Download/Setup Repository\n",
        "print(\"\\n[3/5] 📥 Setting up repository...\")\n",
        "if not Path(\"OAI-inpainting\").exists():\n",
        "    print(\"  📥 Downloading from GitHub...\")\n",
        "    zip_url = \"https://github.com/johnreynolds3d/OAI-inpainting/archive/refs/heads/master.zip\"\n",
        "    zip_path = \"repo.zip\"\n",
        "    urllib.request.urlretrieve(zip_url, zip_path)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(\".\")\n",
        "\n",
        "    if Path(\"OAI-inpainting-master\").exists():\n",
        "        Path(\"OAI-inpainting-master\").rename(\"OAI-inpainting\")\n",
        "    Path(zip_path).unlink()\n",
        "    print(\"  ✅ Repository downloaded\")\n",
        "else:\n",
        "    print(\"  ✅ Repository already exists\")\n",
        "\n",
        "os.chdir(\"OAI-inpainting\")\n",
        "sys.path.insert(0, str(Path.cwd()))\n",
        "\n",
        "# 4. Setup data and results symlinks\n",
        "print(\"\\n[4/5] 🔗 Setting up data and results links...\")\n",
        "data_dir = Path(\"data\")\n",
        "results_dir = Path(\"results\")\n",
        "relative_data = Path(\"../OAI_untracked/data\")\n",
        "relative_results = Path(\"../OAI_untracked/results\")\n",
        "\n",
        "# Remove broken symlinks\n",
        "for name in [\"data\", \"results\"]:\n",
        "    p = Path(name)\n",
        "    if p.is_file():\n",
        "        p.unlink()\n",
        "\n",
        "# Setup data symlink\n",
        "if not data_dir.exists():\n",
        "    if relative_data.exists():\n",
        "        data_dir.symlink_to(relative_data)\n",
        "        print(f\"  ✅ Data linked: {data_dir.resolve()}\")\n",
        "    else:\n",
        "        print(f\"  ⚠️  OAI_untracked/data not found. Expected at: {relative_data.resolve()}\")\n",
        "else:\n",
        "    print(\"  ✅ Data already linked\")\n",
        "\n",
        "# Setup results symlink (same as local - results persist in Google Drive!)\n",
        "if not results_dir.exists():\n",
        "    # Ensure parent results directory exists\n",
        "    if not relative_results.exists():\n",
        "        try:\n",
        "            relative_results.mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"  📁 Created results directory in OAI_untracked\")\n",
        "        except:\n",
        "            pass  # May not have permissions, will fallback\n",
        "    \n",
        "    # Try to create symlink\n",
        "    if relative_results.exists():\n",
        "        results_dir.symlink_to(relative_results)\n",
        "        print(f\"  ✅ Results linked: {results_dir.resolve()}\")\n",
        "        print(f\"  💾 Results will persist in Google Drive!\")\n",
        "    else:\n",
        "        # Fallback: create local directory\n",
        "        results_dir.mkdir(exist_ok=True)\n",
        "        print(f\"  ⚠️  Results created as local directory (won't persist)\")\n",
        "elif results_dir.is_symlink():\n",
        "    print(f\"  ✅ Results already linked: {results_dir.resolve()}\")\n",
        "else:\n",
        "    print(f\"  ⚠️  Results exists as real directory (won't persist in Drive)\")\n",
        "    print(f\"  💡 Delete it to create symlink for persistence\")\n",
        "\n",
        "# 5. Install dependencies\n",
        "print(\"\\n[5/5] 📦 Installing dependencies...\")\n",
        "deps = [\n",
        "    \"torch\",\n",
        "    \"torchvision\",\n",
        "    \"numpy\",\n",
        "    \"opencv-python\",\n",
        "    \"pillow\",\n",
        "    \"scikit-image\",\n",
        "    \"scipy\",\n",
        "    \"pandas\",\n",
        "    \"matplotlib\",\n",
        "    \"seaborn\",\n",
        "    \"pyyaml\",\n",
        "    \"tqdm\",\n",
        "    \"scikit-learn\",\n",
        "]\n",
        "\n",
        "for dep in deps:\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"pip\", \"install\", \"-q\", dep], check=True, capture_output=True, timeout=120\n",
        "        )\n",
        "    except:\n",
        "        pass  # Continue even if some fail\n",
        "\n",
        "print(\"  ✅ Dependencies installed\")\n",
        "\n",
        "# Verify data structure\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"📊 DATA VERIFICATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "oai_img = Path(\"data/oai/img\")\n",
        "if oai_img.exists():\n",
        "    img_count = len(list(oai_img.glob(\"*.png\")))\n",
        "    print(f\"✅ OAI images: {img_count} files\")\n",
        "else:\n",
        "    print(f\"❌ OAI images not found at: {oai_img.resolve()}\")\n",
        "\n",
        "pretrained = Path(\"data/pretrained\")\n",
        "if pretrained.exists():\n",
        "    model_files = list(pretrained.rglob(\"*.pth\")) + list(pretrained.rglob(\"*.pt\"))\n",
        "    print(f\"✅ Pretrained models: {len(model_files)} files\")\n",
        "else:\n",
        "    print(\"⚠️  Pretrained models not found\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"🎉 SETUP COMPLETE! Ready to proceed to Cell 2\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# CELL 2: GENERATE BALANCED DATASET SPLITS (Run Once)\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# Creates 80/10/10 split with perfect BMD balance using ALL 539 images\n",
        "# ⏱️ Time: ~2-5 minutes\n",
        "\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"🔄 GENERATING PERFECTLY BALANCED DATASET SPLITS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "subset_4 = Path(\"data/oai/test/img/subset_4\")\n",
        "\n",
        "# Check if already done\n",
        "if subset_4.exists() and len(list(subset_4.glob(\"*.png\"))) > 0:\n",
        "    print(\"\\n✅ Splits already exist!\")\n",
        "\n",
        "    # Show existing split info\n",
        "    train_count = len(list(Path(\"data/oai/train/img\").glob(\"*.png\")))\n",
        "    val_count = len(list(Path(\"data/oai/valid/img\").glob(\"*.png\")))\n",
        "    test_count = len(list(Path(\"data/oai/test/img\").glob(\"*.png\")))\n",
        "    total = train_count + val_count + test_count\n",
        "\n",
        "    print(f\"\\n📊 Current Split:\")\n",
        "    print(f\"  Train: {train_count} images ({train_count / total * 100:.1f}%)\")\n",
        "    print(f\"  Valid: {val_count} images ({val_count / total * 100:.1f}%)\")\n",
        "    print(f\"  Test:  {test_count} images ({test_count / total * 100:.1f}%)\")\n",
        "    print(f\"  Total: {total} images\")\n",
        "    print(f\"\\n💡 To regenerate, delete: {subset_4}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n🔄 Generating new splits...\")\n",
        "    print(\"This will:\")\n",
        "    print(\"  • Split 539 images into 80/10/10 (train/val/test)\")\n",
        "    print(\"  • Balance low/high BMD in each split\")\n",
        "    print(\"  • Generate masks, edge maps, inverted masks\")\n",
        "    print(\"  • Create subset_4 (4 balanced test images)\")\n",
        "    print(\"\")\n",
        "\n",
        "    result = subprocess.run(\n",
        "        [\"python\", \"split.py\"],\n",
        "        cwd=\"data/oai\",\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        timeout=300,\n",
        "    )\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"✅ SPLITS GENERATED SUCCESSFULLY!\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Show split summary\n",
        "        train_count = len(list(Path(\"data/oai/train/img\").glob(\"*.png\")))\n",
        "        val_count = len(list(Path(\"data/oai/valid/img\").glob(\"*.png\")))\n",
        "        test_count = len(list(Path(\"data/oai/test/img\").glob(\"*.png\")))\n",
        "        total = train_count + val_count + test_count\n",
        "\n",
        "        print(f\"\\n📊 Split Summary:\")\n",
        "        print(f\"  Train: {train_count} images ({train_count / total * 100:.1f}%)\")\n",
        "        print(f\"  Valid: {val_count} images ({val_count / total * 100:.1f}%)\")\n",
        "        print(f\"  Test:  {test_count} images ({test_count / total * 100:.1f}%)\")\n",
        "        print(f\"  Total: {total} images\")\n",
        "        print(\n",
        "            f\"\\n✅ subset_4: {len(list(subset_4.glob('*.png')))} images (2 low BMD + 2 high BMD)\"\n",
        "        )\n",
        "        print(f\"\\n🎯 Each split maintains equal low/high BMD balance\")\n",
        "        print(f\"🎯 All splits are mutually exclusive (no overlap)\")\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n❌ ERROR: Split generation failed\")\n",
        "        print(f\"\\nError output:\\n{result.stderr}\")\n",
        "        print(f\"\\n💡 Try running manually: !cd data/oai && python split.py\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"🎉 READY FOR TESTING/TRAINING! Proceed to Cell 3, 4, or 5\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# CELL 3: QUICK TEST - All 9 Models on Balanced Subset\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# Tests all pretrained models on 4 balanced test images\n",
        "# ⏱️ Time: ~30-60 minutes\n",
        "# 📊 Output: Results in results/ directory + JSON summary\n",
        "\n",
        "import json\n",
        "import sys\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.append(\"scripts\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"🧪 QUICK TEST: Testing All 9 Model Variants\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n📊 Test Configuration:\")\n",
        "print(f\"  • Dataset: subset_4 (4 balanced images)\")\n",
        "print(f\"  • Models: 9 variants (AOT-GAN, ICT, RePaint)\")\n",
        "print(f\"  • Estimated time: 30-60 minutes\")\n",
        "print(f\"  • Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"\")\n",
        "\n",
        "try:\n",
        "    from colab_comprehensive_test import ModelTester\n",
        "\n",
        "    # Run comprehensive test\n",
        "    start_time = time.time()\n",
        "    tester = ModelTester(timeout_per_model=600, verbose=True)\n",
        "    results = tester.run_comprehensive_test(models=[\"all\"])\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    # Display summary\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"🎉 QUICK TEST COMPLETE!\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\n⏱️  Total time: {elapsed / 60:.1f} minutes\")\n",
        "    print(f\"\\n📊 Results Summary:\")\n",
        "    print(f\"  ✅ Successful: {results['summary']['successful']}\")\n",
        "    print(f\"  ❌ Failed: {results['summary']['failed']}\")\n",
        "    print(f\"  ⏭️  Skipped: {results['summary']['skipped']}\")\n",
        "\n",
        "    # List successful models\n",
        "    if results[\"summary\"][\"successful\"] > 0:\n",
        "        print(f\"\\n✅ Successful Models:\")\n",
        "        for r in results[\"results\"]:\n",
        "            if r[\"success\"]:\n",
        "                print(f\"  • {r['model']} ({r['elapsed']:.1f}s)\")\n",
        "\n",
        "    print(f\"\\n📁 Results saved to: results/\")\n",
        "    print(f\"📄 JSON summary: results/comprehensive_test_results.json\")\n",
        "    print(f\"\\n💡 Next steps:\")\n",
        "    print(f\"  • Run Cell 5 for classification evaluation\")\n",
        "    print(f\"  • Run Cell 6 for visual comparison strips\")\n",
        "    print(f\"  • Run Cell 7 to download all results\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"\\n❌ ERROR: Could not import ModelTester\")\n",
        "    print(f\"Error: {e}\")\n",
        "    print(f\"\\n💡 Make sure Cell 1 (setup) completed successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ ERROR during testing: {e}\")\n",
        "    import traceback\n",
        "\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# CELL 4: FULL TRAINING - Train Models on Balanced Dataset\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# Trains models from scratch on 431 balanced training images\n",
        "# ⏱️ Time: ~6-8 hours total\n",
        "# 📊 Output: Trained models + evaluation on 55-image test set\n",
        "\n",
        "import sys\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "sys.path.append(\"scripts\")\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────\n",
        "# CONFIGURATION: Set to True to enable each training phase\n",
        "# ─────────────────────────────────────────────────────────────────\n",
        "\n",
        "TRAIN_AOT_GAN = False  # Set to True to train AOT-GAN (~2-4 hours)\n",
        "TRAIN_ICT = False  # Set to True to train ICT (~1-3 hours)\n",
        "RUN_REPAINT = False  # Set to True to run RePaint inference (~30 min)\n",
        "RUN_EVALUATION = False  # Set to True to evaluate all models (~15 min)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"🎓 FULL TRAINING PIPELINE ON BALANCED DATASET\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n📊 Training Configuration:\")\n",
        "print(f\"  • Training set: 431 images (215 low BMD + 216 high BMD)\")\n",
        "print(f\"  • Validation set: 53 images (26 low BMD + 27 high BMD)\")\n",
        "print(f\"  • Test set: 55 images (28 low BMD + 27 high BMD)\")\n",
        "print(f\"\")\n",
        "print(f\"Enabled phases:\")\n",
        "print(f\"  {'✅' if TRAIN_AOT_GAN else '⏭️ '} AOT-GAN training (~2-4 hours)\")\n",
        "print(f\"  {'✅' if TRAIN_ICT else '⏭️ '} ICT training (~1-3 hours)\")\n",
        "print(f\"  {'✅' if RUN_REPAINT else '⏭️ '} RePaint inference (~30 min)\")\n",
        "print(f\"  {'✅' if RUN_EVALUATION else '⏭️ '} Evaluation (~15 min)\")\n",
        "print(f\"\")\n",
        "\n",
        "if not any([TRAIN_AOT_GAN, TRAIN_ICT, RUN_REPAINT, RUN_EVALUATION]):\n",
        "    print(\"⚠️  No training phases enabled!\")\n",
        "    print(\"\\n💡 To enable training:\")\n",
        "    print(\"  1. Set TRAIN_AOT_GAN = True (or other flags)\")\n",
        "    print(\"  2. Re-run this cell\")\n",
        "    print(\"\\n⏱️  Estimated times:\")\n",
        "    print(\"  • AOT-GAN only: ~2-4 hours\")\n",
        "    print(\"  • ICT only: ~1-3 hours\")\n",
        "    print(\"  • Full pipeline: ~6-8 hours\")\n",
        "    print(\"\\n📊 Benefits of training on balanced split:\")\n",
        "    print(\"  • 2x more training data (431 vs ~216)\")\n",
        "    print(\"  • Equal representation of low/high BMD cases\")\n",
        "    print(\"  • Better model generalization\")\n",
        "    print(\"  • More reliable evaluation metrics\")\n",
        "else:\n",
        "    try:\n",
        "        from colab_pipeline import run_phase\n",
        "\n",
        "        start_time = time.time()\n",
        "        results = []\n",
        "\n",
        "        # Phase 2: AOT-GAN Training\n",
        "        if TRAIN_AOT_GAN:\n",
        "            print(\"\\n\" + \"─\" * 70)\n",
        "            print(\"[1/4] 🔧 Training AOT-GAN...\")\n",
        "            print(\"─\" * 70)\n",
        "            phase_start = time.time()\n",
        "            success = run_phase(2)\n",
        "            phase_time = time.time() - phase_start\n",
        "            results.append((\"AOT-GAN\", success, phase_time))\n",
        "            print(\n",
        "                f\"{'✅' if success else '❌'} AOT-GAN completed in {phase_time / 60:.1f} min\"\n",
        "            )\n",
        "\n",
        "        # Phase 3: ICT Training\n",
        "        if TRAIN_ICT:\n",
        "            print(\"\\n\" + \"─\" * 70)\n",
        "            print(\"[2/4] 🔧 Training ICT...\")\n",
        "            print(\"─\" * 70)\n",
        "            phase_start = time.time()\n",
        "            success = run_phase(3)\n",
        "            phase_time = time.time() - phase_start\n",
        "            results.append((\"ICT\", success, phase_time))\n",
        "            print(\n",
        "                f\"{'✅' if success else '❌'} ICT completed in {phase_time / 60:.1f} min\"\n",
        "            )\n",
        "\n",
        "        # Phase 4: RePaint Inference\n",
        "        if RUN_REPAINT:\n",
        "            print(\"\\n\" + \"─\" * 70)\n",
        "            print(\"[3/4] 🎨 Running RePaint inference...\")\n",
        "            print(\"─\" * 70)\n",
        "            phase_start = time.time()\n",
        "            success = run_phase(4)\n",
        "            phase_time = time.time() - phase_start\n",
        "            results.append((\"RePaint\", success, phase_time))\n",
        "            print(\n",
        "                f\"{'✅' if success else '❌'} RePaint completed in {phase_time / 60:.1f} min\"\n",
        "            )\n",
        "\n",
        "        # Phase 5: Evaluation\n",
        "        if RUN_EVALUATION:\n",
        "            print(\"\\n\" + \"─\" * 70)\n",
        "            print(\"[4/4] 📊 Running evaluation...\")\n",
        "            print(\"─\" * 70)\n",
        "            phase_start = time.time()\n",
        "            success = run_phase(5)\n",
        "            phase_time = time.time() - phase_start\n",
        "            results.append((\"Evaluation\", success, phase_time))\n",
        "            print(\n",
        "                f\"{'✅' if success else '❌'} Evaluation completed in {phase_time / 60:.1f} min\"\n",
        "            )\n",
        "\n",
        "        # Final summary\n",
        "        total_time = time.time() - start_time\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"🎉 TRAINING PIPELINE COMPLETE!\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"\\n⏱️  Total time: {total_time / 3600:.2f} hours\")\n",
        "        print(f\"\\n📊 Phase Results:\")\n",
        "        for name, success, phase_time in results:\n",
        "            status = \"✅\" if success else \"❌\"\n",
        "            print(f\"  {status} {name}: {phase_time / 60:.1f} minutes\")\n",
        "\n",
        "        print(f\"\\n💡 Next steps:\")\n",
        "        print(f\"  • Run Cell 5 for classification evaluation\")\n",
        "        print(f\"  • Run Cell 6 for visual comparison strips\")\n",
        "        print(f\"  • Run Cell 7 to download all results\")\n",
        "\n",
        "    except ImportError as e:\n",
        "        print(f\"\\n❌ ERROR: Could not import training functions\")\n",
        "        print(f\"Error: {e}\")\n",
        "        print(f\"\\n💡 Make sure Cell 1 (setup) completed successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ERROR during training: {e}\")\n",
        "        import traceback\n",
        "\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# CELL 5: CLASSIFICATION EVALUATION\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# Evaluates osteoporosis classification performance on inpainted images\n",
        "# ⏱️ Time: ~5-10 minutes\n",
        "# 📊 Output: Classification accuracy, confusion matrices, detailed metrics\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.append(\"scripts\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"📊 CLASSIFICATION EVALUATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nEvaluating osteoporosis classification on inpainted images...\")\n",
        "print(f\"This will:\")\n",
        "print(f\"  • Load pretrained ResNet50 osteoporosis classifier\")\n",
        "print(f\"  • Test classification on ground truth images\")\n",
        "print(f\"  • Test classification on all model outputs\")\n",
        "print(f\"  • Compare accuracy: GT vs. inpainted images\")\n",
        "print(f\"  • Generate confusion matrices\")\n",
        "print(f\"\")\n",
        "\n",
        "try:\n",
        "    # Note: If colab_classification_evaluation doesn't exist yet,\n",
        "    # this is a placeholder for when you integrate it\n",
        "    try:\n",
        "        from colab_classification_evaluation import run_classification_evaluation\n",
        "\n",
        "        # Run evaluation\n",
        "        results = run_classification_evaluation()\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"🎉 CLASSIFICATION EVALUATION COMPLETE!\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Display results\n",
        "        if results:\n",
        "            print(f\"\\n📊 Classification Performance:\")\n",
        "            print(f\"\\nGround Truth:\")\n",
        "            print(f\"  Accuracy: {results.get('gt_accuracy', 0):.2%}\")\n",
        "\n",
        "            print(f\"\\nModel Comparisons:\")\n",
        "            for model_name, metrics in results.get(\"models\", {}).items():\n",
        "                accuracy = metrics.get(\"accuracy\", 0)\n",
        "                change = metrics.get(\"accuracy_change\", 0)\n",
        "                print(f\"  • {model_name}: {accuracy:.2%} ({change:+.1%} vs GT)\")\n",
        "\n",
        "            print(f\"\\n📁 Results saved to: results/classification/\")\n",
        "            print(\n",
        "                f\"📄 CSV summary: results/classification/classification_results.csv\"\n",
        "            )\n",
        "            print(f\"📊 Confusion matrices: results/classification/confusion_matrices/\")\n",
        "\n",
        "        print(f\"\\n💡 Next steps:\")\n",
        "        print(f\"  • Run Cell 6 for visual comparison strips\")\n",
        "        print(f\"  • Run Cell 7 to download all results\")\n",
        "\n",
        "    except ImportError:\n",
        "        # Fallback: Manual classification using scripts\n",
        "        print(\"\\n⚠️  Integrated classification not available\")\n",
        "        print(\"\\n💡 To run classification evaluation manually:\")\n",
        "        print(\"  !python scripts/colab_classification_evaluation.py\")\n",
        "        print(\"\\nOr implement the colab_classification_evaluation module\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ ERROR during classification evaluation: {e}\")\n",
        "    import traceback\n",
        "\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# CELL 6: GENERATE VISUAL COMPARISON STRIPS\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# Creates horizontal comparison images for visual assessment\n",
        "# ⏱️ Time: ~1-2 minutes\n",
        "# 📊 Output: Comparison strips in results/comparison_strips/\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.append(\"scripts\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"🎨 GENERATING VISUAL COMPARISON STRIPS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nCreating horizontal strips showing:\")\n",
        "print(f\"  GT → GT+Mask → AOT-GAN variants → ICT variants → RePaint variants\")\n",
        "print(f\"\")\n",
        "\n",
        "try:\n",
        "    from generate_comparison_strips import main as generate_strips\n",
        "\n",
        "    # Generate strips\n",
        "    strip_paths = generate_strips()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"🎉 COMPARISON STRIPS GENERATED!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    if strip_paths:\n",
        "        print(f\"\\n✅ Generated {len(strip_paths)} comparison strips\")\n",
        "        print(f\"\\n📁 Location: results/comparison_strips/\")\n",
        "        print(f\"\\n📸 Files created:\")\n",
        "        for path in strip_paths:\n",
        "            print(f\"  • {path.name}\")\n",
        "\n",
        "        print(f\"\\n📊 Also created:\")\n",
        "        print(f\"  • all_comparisons_summary.png (all strips stacked)\")\n",
        "        print(f\"\\n💡 Perfect for visual assessment and publication!\")\n",
        "    else:\n",
        "        print(f\"\\n⚠️  No strips generated\")\n",
        "        print(f\"\\n💡 Make sure you've run:\")\n",
        "        print(f\"  • Cell 3 (quick test) or Cell 4 (training)\")\n",
        "        print(f\"  • Results should be in results/ directory\")\n",
        "\n",
        "    print(f\"\\n💡 Next step:\")\n",
        "    print(f\"  • Run Cell 7 to download all results as ZIP\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"\\n❌ ERROR: Could not import comparison strip generator\")\n",
        "    print(f\"Error: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ ERROR generating strips: {e}\")\n",
        "    import traceback\n",
        "\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# CELL 7: DOWNLOAD ALL RESULTS\n",
        "# ═══════════════════════════════════════════════════════════════════\n",
        "# Packages and downloads all results as a ZIP file\n",
        "# ⏱️ Time: ~2-5 minutes (depends on result size)\n",
        "# 📊 Output: ZIP file downloaded to your local machine\n",
        "\n",
        "import shutil\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"💾 PACKAGING RESULTS FOR DOWNLOAD\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Check if we're in Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"\\n⚠️  Not running in Google Colab\")\n",
        "    print(\"Results are available locally in: results/\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    results_dir = Path(\"results\")\n",
        "\n",
        "    if not results_dir.exists() or not any(results_dir.iterdir()):\n",
        "        print(\"\\n⚠️  No results found to download\")\n",
        "        print(\"\\n💡 Make sure you've run:\")\n",
        "        print(\"  • Cell 3 (quick test) or Cell 4 (training)\")\n",
        "        print(\"  • Results should be in results/ directory\")\n",
        "    else:\n",
        "        # Create ZIP filename with timestamp\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        zip_filename = f\"oai_inpainting_results_{timestamp}.zip\"\n",
        "\n",
        "        print(f\"\\n📦 Creating ZIP archive: {zip_filename}\")\n",
        "        print(\"This may take a few minutes...\")\n",
        "        print(\"\")\n",
        "\n",
        "        # Create ZIP file\n",
        "        file_count = 0\n",
        "        with zipfile.ZipFile(zip_filename, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "            for file_path in results_dir.rglob(\"*\"):\n",
        "                if file_path.is_file():\n",
        "                    arcname = file_path.relative_to(results_dir.parent)\n",
        "                    zipf.write(file_path, arcname)\n",
        "                    file_count += 1\n",
        "\n",
        "                    # Show progress for large files\n",
        "                    if file_count % 50 == 0:\n",
        "                        print(f\"  Packed {file_count} files...\")\n",
        "\n",
        "        zip_size = Path(zip_filename).stat().st_size / 1024 / 1024\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"✅ ARCHIVE CREATED!\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"\\n📦 File: {zip_filename}\")\n",
        "        print(f\"📊 Size: {zip_size:.1f} MB\")\n",
        "        print(f\"📁 Files: {file_count} total\")\n",
        "        print(f\"\")\n",
        "        print(f\"⬇️  Initiating download...\")\n",
        "\n",
        "        # Download the file\n",
        "        try:\n",
        "            files.download(zip_filename)\n",
        "            print(f\"\\n✅ Download initiated!\")\n",
        "            print(f\"💡 Check your browser's download folder\")\n",
        "            print(f\"\")\n",
        "            print(f\"📊 Your ZIP contains:\")\n",
        "            print(f\"  • Inpainted images from all models\")\n",
        "            print(f\"  • Comprehensive test results (JSON)\")\n",
        "            print(f\"  • Classification evaluation (if run)\")\n",
        "            print(f\"  • Visual comparison strips (if run)\")\n",
        "            print(f\"  • All metrics and evaluations\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Download failed: {e}\")\n",
        "            print(f\"💡 Try downloading manually: files.download('{zip_filename}')\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"🎉 WORKFLOW COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n📊 Summary of what you accomplished:\")\n",
        "print(f\"  ✅ Setup complete environment\")\n",
        "print(f\"  ✅ Generated balanced dataset splits (539 images)\")\n",
        "print(f\"  ✅ Tested/trained models on balanced data\")\n",
        "print(f\"  ✅ Evaluated performance and classification\")\n",
        "print(f\"  ✅ Created visualizations for analysis\")\n",
        "print(f\"  ✅ Downloaded all results\")\n",
        "print(f\"\\n💡 Your results are ready for analysis!\")\n",
        "print(f\"\\n📚 Next steps:\")\n",
        "print(f\"  • Analyze results in your downloaded ZIP\")\n",
        "print(f\"  • Use comparison strips in your publication\")\n",
        "print(f\"  • Review classification metrics\")\n",
        "print(f\"  • Consider training with different hyperparameters (Cell 4)\")\n",
        "print(f\"\\n🔄 To run again:\")\n",
        "print(f\"  • Cell 3: Test with different models\")\n",
        "print(f\"  • Cell 4: Train with different configurations\")\n",
        "print(f\"  • Cell 5-7: Re-evaluate and visualize\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
