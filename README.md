# OAI X-ray Inpainting Project

Comprehensive implementation and comparison of state-of-the-art deep learning inpainting methods for wrist X-ray image analysis on the Osteoarthritis Initiative (OAI) dataset.

### üìì Google Colab Notebooks

**üöÄ Streamlined (Recommended)** - 7 cells, one-click actions
[![Open Streamlined](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/johnreynolds3d/OAI-inpainting/blob/master/notebooks/OAI_Inpainting_Streamlined.ipynb)

**üìö Full Version** - 30+ cells, detailed control
[![Open Full](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/johnreynolds3d/OAI-inpainting/blob/master/notebooks/OAI_Inpainting_Colab.ipynb)

---

## üìë Table of Contents

- [Overview](#-overview)
- [Quick Start](#-quick-start)
  - [Google Colab (Recommended)](#option-1-google-colab-recommended)
  - [Local Installation](#option-2-local-installation)
- [Comprehensive Testing](#-comprehensive-testing)
- [Training Models](#-training-models)
- [Testing & Evaluation](#-testing--evaluation)
- [Data Management](#-data-management)
- [Configuration](#-configuration)
- [Results](#-results)
- [Development](#-development)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)

---

## üéØ Overview

This project implements and compares **three state-of-the-art inpainting methods** for medical X-ray analysis:

- **AOT-GAN** - Attention-based Outpainting Transformer GAN
- **ICT** - Image Completion Transformer
- **RePaint** - Repaint-based diffusion model for inpainting

### üé® Visual Results

Side-by-side comparison of all model variants on OAI wrist X-rays:

![Model Comparison](results_tracked/comparison_strips/all_comparisons_summary.png)

*From left to right: Ground Truth | Masked Input | 8 Model Variants (AOT-GAN: CelebA-HQ, Places2 | ICT: FFHQ, ImageNet, Places2_Nature | RePaint: CelebA-HQ, ImageNet, Places2)*

**Key Findings:**
- üèÜ **AOT-GAN CelebA-HQ**: Best overall performance (19.92 dB PSNR)
- üìä **Quantitative metrics**: PSNR, SSIM, MAE calculated for all variants
- üî¨ **Balanced dataset**: 539 images split 80/10/10 (train/val/test) with equal low/high BMD distribution

### Model Variants Available

Each architecture has been pretrained on multiple datasets, giving you **9 total model variants** to test:

| Model | Variants | Use Case |
|-------|----------|----------|
| **AOT-GAN** | CelebA-HQ, Places2, OAI | Fast GAN-based inpainting |
| **ICT** | FFHQ, ImageNet, Places2_Nature, OAI | Transformer-based completion |
| **RePaint** | CelebA-HQ, ImageNet, Places2 | Diffusion-based high-quality |

### Key Features

‚úÖ **Git-tracked scripts** - Pull latest updates automatically in Colab
‚úÖ **Comprehensive testing** - Test all 9 models with one command
‚úÖ **Platform-agnostic** - Works on Linux, macOS, Windows, and Colab
‚úÖ **Production-ready** - Pre-commit hooks, linting, type checking
‚úÖ **Well-documented** - Extensive guides and examples

---

## üöÄ Quick Start

### Option 1: Google Colab (Recommended)

**Best for:** Quick testing, no local GPU required, cloud-based training

Choose your workflow:
- **Streamlined Notebook** (7 cells) - Simple, efficient, recommended for most users
- **Full Notebook** (30+ cells) - Detailed control, all options exposed

**Colab Link:** https://colab.research.google.com/github/johnreynolds3d/OAI-inpainting/blob/master/notebooks/OAI_Inpainting_Colab.ipynb

#### Setup Steps:

**1. Upload Data to Google Drive**

Upload the `OAI_untracked/` directory to:
```
/content/drive/MyDrive/Colab Notebooks/OAI_untracked/
```

Expected structure:
```
OAI_untracked/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ oai/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ img/          # 539 PNG X-ray images (~11.6 MB)
‚îÇ   ‚îî‚îÄ‚îÄ pretrained/       # Model checkpoint files (~16GB)
‚îÇ       ‚îú‚îÄ‚îÄ aot-gan/
‚îÇ       ‚îú‚îÄ‚îÄ ict/
‚îÇ       ‚îî‚îÄ‚îÄ repaint/
‚îî‚îÄ‚îÄ README.md
```

**Upload requirements:**
- Total size: ~16GB
- Upload time: 30-60 minutes (depending on connection)
- Required: OAI images (~11.6 MB)
- Optional but recommended: Pretrained models (~16GB)

**‚ö†Ô∏è CRITICAL: Directory Structure**

Both directories **MUST be siblings** in `Colab Notebooks/`:
```
/content/drive/MyDrive/Colab Notebooks/
‚îú‚îÄ‚îÄ OAI-inpainting/      # ‚Üê Cloned from GitHub (automatic)
‚îî‚îÄ‚îÄ OAI_untracked/       # ‚Üê Your uploaded data
    ‚îú‚îÄ‚îÄ data/            # ‚Üê OAI images & pretrained models
    ‚îî‚îÄ‚îÄ results/         # ‚Üê Will be created for outputs
```

This sibling structure enables **relative symlinks** that work identically on local & Colab:
- `data -> ../OAI_untracked/data/`
- `results -> ../OAI_untracked/results/`

**2. Run the Colab Notebook**

Click the "Open in Colab" badge above. The notebook will automatically:
- ‚úÖ Clone to `Colab Notebooks/OAI-inpainting/` (sibling to your data)
- ‚úÖ Mount Google Drive
- ‚úÖ Create relative symlinks (platform-agnostic!)
- ‚úÖ Generate train/valid/test splits
- ‚úÖ Create masks and edge maps

**3. Test All Models (Recommended - 30-60 minutes)**

Run Cell 11 in the notebook:
```python
tester = ModelTester(timeout_per_model=600)
results = tester.run_comprehensive_test(models=["all"])
```

Tests all 9 model variants with **results saved to Google Drive**!

**4. Or Train New Models (Optional - 6-8 hours)**

Run Cell 14+ for full training pipeline. **All outputs persist in Google Drive!**

### Option 2: Local Installation

**Best for:** Development, custom experiments, full control

**Works anywhere!** You can clone to any directory as long as `OAI_untracked/` is a sibling.

```bash
# 1. Navigate to your preferred parent directory (can be anywhere!)
cd /your/preferred/location/

# 2. Clone repository
git clone https://github.com/johnreynolds3d/OAI-inpainting.git
cd OAI-inpainting

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate   # Windows

# 3. Install dependencies
pip install -e ".[dev,ml]"

# 4. Install pre-commit hooks (for development)
pre-commit install

# 5. Setup data and results with symlinks (OPTION A: Recommended)
# Use RELATIVE symlinks for platform-agnostic paths
# Both directories must be siblings (same parent directory)
ln -s ../OAI_untracked/data/ data
ln -s ../OAI_untracked/results/ results
# Verify: ls data/oai/img/*.png | wc -l  # Should show 539

# 5. Setup data (OPTION B: Copy files)
python scripts/setup_data.py
# Or specify custom location:
# python scripts/setup_data.py --source-dir /path/to/OAI_untracked
# Note: results/ directory will still be created locally

# 6. Generate dataset splits
cd data/oai
python split.py
cd ../..
```

**Note on Data & Results Setup:**
- **Option A (Symlink - Recommended)**:
  - ‚úÖ **Universal**: Works in ANY directory location
  - ‚úÖ **Portable**: Move both directories together, symlinks still work
  - ‚úÖ **Space-efficient**: Saves ~16GB (no data duplication)
  - ‚úÖ **Single source**: One data location, multiple project clones possible
  - ‚úÖ **Persistent results**: Survives Git operations (checkout, clean, reset)
  - ‚úÖ **Colab-compatible**: Same structure on local and Google Drive
  - ‚ö†Ô∏è  Requires: Both directories must be siblings (same parent directory)
  - ‚ö†Ô∏è  Platform: Linux/macOS native, Windows needs admin for symlinks
- **Option B (Copy)**:
  - Works on all platforms including Windows
  - Uses more disk space (~16GB duplicated)
  - Results stored locally in project directory
  - Data tied to one project clone

---

## üß™ Comprehensive Testing

**The fastest way to test all model variants on your OAI data.**

### Command Line

```bash
# Test all 9 model variants (recommended)
python scripts/colab_comprehensive_test.py --models all

# Test specific model families
python scripts/colab_comprehensive_test.py --models aot-gan
python scripts/colab_comprehensive_test.py --models ict repaint

# Adjust timeout (default: 600 seconds per model)
python scripts/colab_comprehensive_test.py --timeout 900
```

### Python API

```python
from scripts.colab_comprehensive_test import ModelTester

# Test all models
tester = ModelTester(timeout_per_model=600, verbose=True)
results = tester.run_comprehensive_test(models=["all"])

# Check results
print(f"‚úÖ Successful: {results['summary']['successful']}")
print(f"‚ùå Failed: {results['summary']['failed']}")
print(f"‚è≠Ô∏è Skipped: {results['summary']['skipped']}")

# Access detailed results
for result in results['results']:
    if result['success']:
        print(f"{result['model']}: {result['elapsed']:.1f}s")
```

### What Gets Tested

| Model Family | Variants | Test Images | Expected Time |
|--------------|----------|-------------|---------------|
| **AOT-GAN** | CelebA-HQ, Places2, OAI | 4 X-rays | ~6-9 min |
| **ICT** | FFHQ, ImageNet, Places2_Nature, OAI | 4 X-rays | ~12-16 min |
| **RePaint** | CelebA-HQ, ImageNet, Places2 | 4 X-rays | ~18-24 min |
| **Total** | 9 variants | 4 X-rays | **~30-60 min** |

*Test set: 4 OAI X-ray images from subset_4 (2 low BMD, 2 high BMD - perfectly balanced)*

### Output

Results are organized by model variant:

```
results/
‚îú‚îÄ‚îÄ comprehensive_test_results.json  # Summary with metrics
‚îú‚îÄ‚îÄ AOT-GAN/
‚îÇ   ‚îú‚îÄ‚îÄ CelebA-HQ/subset_4/         # Inpainted images
‚îÇ   ‚îú‚îÄ‚îÄ Places2/subset_4/
‚îÇ   ‚îî‚îÄ‚îÄ OAI/subset_4/
‚îú‚îÄ‚îÄ ICT/
‚îÇ   ‚îú‚îÄ‚îÄ FFHQ/subset_4/
‚îÇ   ‚îú‚îÄ‚îÄ ImageNet/subset_4/
‚îÇ   ‚îú‚îÄ‚îÄ Places2_Nature/subset_4/
‚îÇ   ‚îî‚îÄ‚îÄ OAI/subset_4/
‚îî‚îÄ‚îÄ RePaint/
    ‚îú‚îÄ‚îÄ CelebA-HQ/subset_4/
    ‚îú‚îÄ‚îÄ ImageNet/subset_4/
    ‚îî‚îÄ‚îÄ Places2/subset_4/
```

**JSON results file contains:**
- Timestamp and duration
- Success/failure status for each model
- Execution time per model
- Output directory paths
- Error messages (if any)

---

## üéì Training Models

### Train Individual Models

```bash
# Train AOT-GAN on OAI data
python scripts/train.py --model aot-gan --config configs/oai_config.yml

# Train ICT on OAI data
python scripts/train.py --model ict --config configs/oai_config.yml

# Note: RePaint is inference-only (pretrained diffusion model)
```

### Training Pipeline (Google Colab)

For full training pipeline in Colab:

```python
from scripts.colab_pipeline import run_full_pipeline, run_phase

# Run complete pipeline (6-8 hours)
run_full_pipeline(timeout_hours=8)

# Or run individual phases:
run_phase(1)  # Quick verification (5 min)
run_phase(2)  # AOT-GAN training (2-4 hours)
run_phase(3)  # ICT training (1-3 hours)
run_phase(4)  # RePaint inference (30 min)
run_phase(5)  # Evaluation (15 min)
```

### Training Configuration

Customize training via YAML configs:

```yaml
# configs/oai_config.yml (AOT-GAN example)
data:
  train_images: "./data/oai/train/img"
  train_masks: "./data/oai/train/mask"

model:
  name: "aotgan"
  block_num: 8
  rates: "1+2+4+8"
  gan_type: "smgan"

training:
  batch_size: 8
  image_size: 512
  lr_g: 1e-4
  lr_d: 1e-4
  max_epochs: 100
```

See [Configuration](#-configuration) section for more details.

---

## üß™ Testing & Evaluation

### Individual Model Testing

```bash
# Test AOT-GAN
python scripts/test.py --model aot-gan --config configs/oai_config.yml

# Test ICT
python scripts/test.py --model ict --config configs/oai_config.yml

# Test RePaint
python scripts/test.py --model repaint --config configs/oai_config.yml
```

### Evaluation & Metrics

```bash
# Evaluate all models on subset_4
python scripts/evaluate.py --models aot-gan ict repaint --subset subset_4

# Evaluate on full test set
python scripts/evaluate.py --models all --subset test

# Custom output directory
python scripts/evaluate.py --models aot-gan --output results/custom_eval/
```

**Metrics calculated:**
- **Inpainting Quality**: PSNR, SSIM, L1 distance
- **Classification**: Accuracy, Precision, Recall, F1-score
- **Statistical**: Paired t-tests, confidence intervals
- **Visual**: Side-by-side comparisons, difference maps

---

## üìä Data Management

### Dataset Structure

```
data/
‚îú‚îÄ‚îÄ oai/
‚îÇ   ‚îú‚îÄ‚îÄ img/              # Original 539 OAI X-ray images
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img/          # Training images
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mask/         # Random square masks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mask_inv/     # Inverted masks (for RePaint)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ edge/         # Canny edge maps (for ICT)
‚îÇ   ‚îú‚îÄ‚îÄ valid/            # Validation split
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mask/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mask_inv/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ edge/
‚îÇ   ‚îî‚îÄ‚îÄ test/             # Test split
‚îÇ       ‚îú‚îÄ‚îÄ img/
‚îÇ       ‚îú‚îÄ‚îÄ mask/
‚îÇ       ‚îú‚îÄ‚îÄ mask_inv/
‚îÇ       ‚îú‚îÄ‚îÄ edge/
‚îÇ       ‚îî‚îÄ‚îÄ subset_4/     # 4-image evaluation subset
‚îÇ           ‚îú‚îÄ‚îÄ img/
‚îÇ           ‚îú‚îÄ‚îÄ mask/
‚îÇ           ‚îú‚îÄ‚îÄ mask_inv/
‚îÇ           ‚îú‚îÄ‚îÄ edge/
‚îÇ           ‚îî‚îÄ‚îÄ subset_4_info.csv
‚îî‚îÄ‚îÄ pretrained/
    ‚îú‚îÄ‚îÄ aot-gan/
    ‚îÇ   ‚îú‚îÄ‚îÄ celebahq/     # CelebA-HQ pretrained
    ‚îÇ   ‚îú‚îÄ‚îÄ places2/      # Places2 pretrained
    ‚îÇ   ‚îî‚îÄ‚îÄ OAI/          # OAI-trained (if available)
    ‚îú‚îÄ‚îÄ ict/
    ‚îÇ   ‚îú‚îÄ‚îÄ Transformer/
    ‚îÇ   ‚îî‚îÄ‚îÄ Upsample/
    ‚îÇ       ‚îú‚îÄ‚îÄ FFHQ/
    ‚îÇ       ‚îú‚îÄ‚îÄ ImageNet/
    ‚îÇ       ‚îú‚îÄ‚îÄ Places2_Nature/
    ‚îÇ       ‚îî‚îÄ‚îÄ OAI/      # OAI-trained (if available)
    ‚îî‚îÄ‚îÄ repaint/
        ‚îú‚îÄ‚îÄ 256x256_classifier.pt
        ‚îú‚îÄ‚îÄ 256x256_diffusion.pt
        ‚îú‚îÄ‚îÄ celeba256_250000.pt
        ‚îî‚îÄ‚îÄ places256_300000.pt
```

### Data Setup Script

```bash
# Auto-detect and setup data (searches common locations)
python scripts/setup_data.py

# Preview what would be copied (dry run)
python scripts/setup_data.py --dry-run

# Specify custom source directory
python scripts/setup_data.py --source-dir /path/to/OAI_untracked

# Force overwrite existing files
python scripts/setup_data.py --force
```

**What the script does:**
- ‚úÖ Auto-detects OAI_untracked directory in common locations
- ‚úÖ Validates data structure and file counts
- ‚úÖ Estimates disk space requirements
- ‚úÖ Copies data with progress tracking
- ‚úÖ Handles missing optional components gracefully
- ‚úÖ Provides detailed error messages

### Generating Dataset Splits

After data setup, generate splits and auxiliary data:

```bash
cd data/oai
python split.py
```

**This creates:**
- ‚úÖ **Perfectly balanced train/valid/test splits** (80%/10%/10%)
  - Uses **ALL 539 images** with mutually exclusive splits
  - Each split maintains **exact 50/50 balance** of low BMD vs high BMD
  - Stratified by BMD threshold (median BMD = classification boundary)
- ‚úÖ **Random square masks** for inpainting tasks
- ‚úÖ **Canny edge maps** for ICT model's edge-aware inpainting
- ‚úÖ **subset_4 evaluation set**: 2 low BMD + 2 high BMD images for quick testing

**Split details:**
- **Training**: 80% (431 images: ~216 low BMD, ~215 high BMD)
- **Validation**: 10% (54 images: ~27 low BMD, ~27 high BMD)
- **Testing**: 10% (54 images: ~27 low BMD, ~27 high BMD)
- **Total**: 539 images (100% of available data)
- **Balance**: Every split maintains equal low/high BMD representation
- **Exclusivity**: No image appears in multiple splits

---

## ‚öôÔ∏è Configuration

All models use platform-agnostic YAML configuration files in the `configs/` directory.

### Configuration Files

```
configs/
‚îú‚îÄ‚îÄ oai_config.yml        # Main config for OAI dataset
‚îî‚îÄ‚îÄ subset_4_config.yml   # Config for subset_4 evaluation
```

### AOT-GAN Configuration

```yaml
# Example: configs/oai_config.yml
data:
  train_images: "./data/oai/train/img"
  train_masks: "./data/oai/train/mask"
  test_images: "./data/oai/test/img/subset_4"
  test_masks: "./data/oai/test/mask/subset_4"

model:
  name: "aotgan"
  block_num: 8
  rates: "1+2+4+8"
  gan_type: "smgan"

training:
  batch_size: 8
  image_size: 512
  lr_g: 1e-4
  lr_d: 1e-4
  max_epochs: 100
  num_workers: 4

hardware:
  distributed: false
  tensorboard: true

paths:
  save_dir: "./results/logs/aot-gan"
  outputs: "./results/AOT-GAN/OAI"
  resume: null  # or path to checkpoint
```

### ICT Configuration

```yaml
# Example: configs/oai_config.yml
MODE: 2          # 1=train, 2=test, 3=eval
MODEL: 2
MASK: 3
EDGE: 1
GPU: [0]
SEED: 10

# Dataset paths
TRAIN_FLIST: "./data/oai/train/img"
VAL_FLIST: "./data/oai/valid/img"
TEST_FLIST: "./data/oai/test/img"

TRAIN_EDGE_FLIST: "./data/oai/train/edge"
VAL_EDGE_FLIST: "./data/oai/valid/edge"
TEST_EDGE_FLIST: "./data/oai/test/edge"

TRAIN_MASK_FLIST: "./data/oai/train/mask"
VAL_MASK_FLIST: "./data/oai/valid/mask"
TEST_MASK_FLIST: "./data/oai/test/mask"

# Training parameters
LR: 0.0001
BATCH_SIZE: 32
INPUT_SIZE: 256
MAX_ITERS: 5e6

# Paths
PATH: "./results/logs/ict"
RESULTS: "./results/ICT/OAI"
```

### RePaint Configuration

RePaint uses specialized configs generated per test run. See `scripts/colab_comprehensive_test.py` for examples.

---

## üìà Results

### Results Directory Structure

```
results/
‚îú‚îÄ‚îÄ comprehensive_test_results.json  # Summary from comprehensive testing
‚îú‚îÄ‚îÄ AOT-GAN/
‚îÇ   ‚îú‚îÄ‚îÄ CelebA-HQ/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ subset_4/               # Inpainted images
‚îÇ   ‚îú‚îÄ‚îÄ Places2/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ subset_4/
‚îÇ   ‚îî‚îÄ‚îÄ OAI/
‚îÇ       ‚îî‚îÄ‚îÄ subset_4/
‚îú‚îÄ‚îÄ ICT/
‚îÇ   ‚îú‚îÄ‚îÄ FFHQ/subset_4/
‚îÇ   ‚îú‚îÄ‚îÄ ImageNet/subset_4/
‚îÇ   ‚îú‚îÄ‚îÄ Places2_Nature/subset_4/
‚îÇ   ‚îî‚îÄ‚îÄ OAI/subset_4/
‚îú‚îÄ‚îÄ RePaint/
‚îÇ   ‚îú‚îÄ‚îÄ CelebA-HQ/subset_4/
‚îÇ   ‚îú‚îÄ‚îÄ ImageNet/subset_4/
‚îÇ   ‚îî‚îÄ‚îÄ Places2/subset_4/
‚îú‚îÄ‚îÄ metrics/                        # Quantitative metrics
‚îÇ   ‚îú‚îÄ‚îÄ psnr_ssim_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ classification_results.csv
‚îÇ   ‚îî‚îÄ‚îÄ statistical_tests.json
‚îú‚îÄ‚îÄ plots/                          # Visualizations
‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.png
‚îÇ   ‚îú‚îÄ‚îÄ training_curves.png
‚îÇ   ‚îî‚îÄ‚îÄ quality_metrics.png
‚îî‚îÄ‚îÄ logs/                           # Training/inference logs
    ‚îú‚îÄ‚îÄ aot-gan/
    ‚îú‚îÄ‚îÄ ict/
    ‚îî‚îÄ‚îÄ repaint/
```

### Analyzing Results

```python
import json
from pathlib import Path

# Load comprehensive test results
results_file = Path("results/comprehensive_test_results.json")
with results_file.open() as f:
    results = json.load(f)

# Print summary
print(f"Total tests: {results['summary']['total']}")
print(f"Successful: {results['summary']['successful']}")
print(f"Duration: {results['duration']}")

# Analyze individual models
for result in results['results']:
    if result['success']:
        print(f"{result['model']}: {result['elapsed']:.1f}s")
        print(f"  Output: {result['output_dir']}")
```

### Evaluation Metrics

**Inpainting Quality Metrics:**
- **PSNR** (Peak Signal-to-Noise Ratio): Higher is better (typically 20-40 dB)
- **SSIM** (Structural Similarity Index): Higher is better (0-1 scale)
- **L1 Loss**: Lower is better (pixel-wise difference)

**Classification Metrics:**
- **Accuracy**: Overall correctness
- **Precision/Recall**: Class-specific performance
- **F1-Score**: Harmonic mean of precision/recall
- **Confusion Matrix**: Detailed class predictions

---

## üõ†Ô∏è Development

### Code Quality Tools

This project uses modern Python development tools:

- **Ruff**: Fast linter and formatter (replaces Black + flake8 + isort)
- **MyPy**: Static type checking
- **Pre-commit**: Automated code quality checks
- **Pytest**: Testing framework with coverage

### Development Commands

```bash
# Format code
ruff format .

# Lint code
ruff check .

# Fix linting issues automatically
ruff check . --fix

# Run type checking
mypy src/ scripts/

# Run tests
pytest tests/

# Run tests with coverage
pytest tests/ --cov=src --cov-report=html
```

### Pre-commit Hooks

The project includes pre-commit hooks that automatically:
- ‚úÖ Format code with Ruff
- ‚úÖ Check for linting issues
- ‚úÖ Validate YAML/JSON files
- ‚úÖ Check for large files
- ‚úÖ Ensure proper line endings
- ‚úÖ Check for merge conflicts

Install hooks:
```bash
pre-commit install
```

### Project Structure

```
OAI-inpainting/
‚îú‚îÄ‚îÄ configs/                    # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ oai_config.yml
‚îÇ   ‚îî‚îÄ‚îÄ subset_4_config.yml
‚îú‚îÄ‚îÄ scripts/                    # Main scripts
‚îÇ   ‚îú‚îÄ‚îÄ train.py               # Training script
‚îÇ   ‚îú‚îÄ‚îÄ test.py                # Testing script
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py            # Evaluation script
‚îÇ   ‚îú‚îÄ‚îÄ setup_data.py          # Data setup
‚îÇ   ‚îú‚îÄ‚îÄ colab_pipeline.py      # Colab training pipeline
‚îÇ   ‚îî‚îÄ‚îÄ colab_comprehensive_test.py  # Comprehensive testing
‚îú‚îÄ‚îÄ src/                       # Core source code
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ paths.py              # Path utilities
‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Config management
‚îÇ   ‚îú‚îÄ‚îÄ data.py               # Data loaders
‚îÇ   ‚îú‚îÄ‚îÄ experiment_tracking.py
‚îÇ   ‚îî‚îÄ‚îÄ data_versioning.py
‚îú‚îÄ‚îÄ models/                    # Model implementations
‚îÇ   ‚îú‚îÄ‚îÄ aot-gan/              # AOT-GAN implementation
‚îÇ   ‚îú‚îÄ‚îÄ ict/                  # ICT implementation
‚îÇ   ‚îú‚îÄ‚îÄ repaint/              # RePaint implementation
‚îÇ   ‚îî‚îÄ‚îÄ classifier/           # Classification utilities
‚îú‚îÄ‚îÄ data/                      # Data (not tracked)
‚îÇ   ‚îú‚îÄ‚îÄ oai/                  # OAI dataset
‚îÇ   ‚îî‚îÄ‚îÄ pretrained/           # Pretrained models
‚îú‚îÄ‚îÄ results/                   # Results (not tracked)
‚îú‚îÄ‚îÄ tests/                     # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îî‚îÄ‚îÄ integration/
‚îú‚îÄ‚îÄ notebooks/                 # Jupyter notebooks
‚îÇ   ‚îî‚îÄ‚îÄ OAI_Inpainting_Colab.ipynb
‚îú‚îÄ‚îÄ docs/                      # Documentation
‚îú‚îÄ‚îÄ pyproject.toml            # Project metadata
‚îú‚îÄ‚îÄ requirements-dev.txt      # Dev dependencies
‚îî‚îÄ‚îÄ README.md                 # This file
```

---

## üì§ Sharing Data with Collaborators

### For Data Owners: How to Share

**Goal:** Share your OAI data with collaborators while keeping results private.

**1. Share Data Folder (Read-Only)**

In Google Drive:
1. Navigate to: `/MyDrive/Colab Notebooks/OAI_untracked/data/`
2. Right-click on `data` folder ‚Üí Share ‚Üí Share
3. Set: **"Anyone with the link"** + **"Viewer"** (read-only)
4. Copy and share the link

**Important:** Only share `data/` folder, NOT `results/`!

**2. Share Instructions**

Provide users with:
```
üì• OAI Inpainting Shared Data

Sharing Link: [your-link-here]

Setup:
1. Click link ‚Üí "Add shortcut to Drive"
2. See README.md "Using Shared Data" section
3. Run Colab notebook
4. Results save to YOUR OWN directory

Data is read-only - your results stay private!
```

### For Data Consumers: Using Shared Data

**If using someone's shared read-only data:**

**Option A: Manual Copy in Colab**

```python
# In a Colab cell after mounting Drive and cloning repo:
from pathlib import Path
import shutil

# Copy shared data (update path to your shortcut location)
shared_path = Path("/content/drive/MyDrive/[shortcut-name]/data")
shutil.copytree(shared_path, "data", dirs_exist_ok=True)

# Create YOUR OWN results directory
Path("../OAI_untracked/results").mkdir(parents=True, exist_ok=True)
Path("results").symlink_to("../OAI_untracked/results/")

print("‚úÖ Data copied from shared source")
print("‚úÖ Results will save to YOUR directory")
```

**Option B: Get Your Own Copy**

Ask the data owner to share the data, then:
1. Download the shared data to your local machine
2. Upload to your own Google Drive: `Colab Notebooks/OAI_untracked/data/`
3. Follow the normal setup (Cell 3 creates symlinks automatically)

**Your directory structure with shared data:**
```
/content/drive/MyDrive/
‚îú‚îÄ‚îÄ [Shared Data Shortcut]/  ‚Üê Read-only access to owner's data
‚îÇ   ‚îî‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ Colab Notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ OAI-inpainting/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/            ‚Üê Local copy from shared (temporary)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ results/         ‚Üí ../OAI_untracked/results/ (yours!)
‚îÇ   ‚îî‚îÄ‚îÄ OAI_untracked/
‚îÇ       ‚îî‚îÄ‚îÄ results/         ‚Üê YOUR outputs (isolated from owner)
```

**Benefits:**
- ‚úÖ No need to store 16GB in your Drive
- ‚úÖ Your results completely separate from owner's
- ‚úÖ Quick access to latest shared data
- ‚úÖ Original data protected (read-only)

**Trade-offs:**
- ‚ö†Ô∏è Data copied to local Colab (lost on disconnect - just re-copy)
- ‚ö†Ô∏è Manual setup needed (not automatic like own data)

### Security & Privacy

**For Data Owners:**
- ‚úÖ Safe to share: `data/` folder (images, models)
- ‚ùå Don't share: `results/` folder (experiments, outputs)
- ‚úÖ Read-only prevents modifications to your data

**For Data Consumers:**
- ‚úÖ Your results: Saved to YOUR Drive space
- ‚úÖ Your privacy: No access to owner's results
- ‚úÖ Your experiments: Remain private

---

## üîß Troubleshooting

### Google Colab Issues

#### "OAI data not found in Google Drive"
**Solution:**
- Verify data is at: `/content/drive/MyDrive/Colab Notebooks/OAI_untracked/`
- Check Google Drive is mounted: Run the Drive mount cell
- Ensure directory structure matches expected format

#### "Upload failed or incomplete"
**Solution:**
- Large files (>1GB) may timeout - upload in batches
- Check Google Drive storage space (need 16GB+)
- Verify stable internet connection
- Try uploading via Google Drive web interface instead

#### "Can't access files" or "Permission denied"
**Solution:**
- Ensure files are in "My Drive", not "Shared with me"
- Check file sharing permissions in Google Drive
- Try copying files to a new folder in My Drive

#### "subset_4 data not found"
**Solution:**
- Run the data split generation: `cd data/oai && python split.py`
- Check that split.py ran successfully without errors
- Verify 4 images exist in each subset_4 subdirectory

### Local Installation Issues

#### "Could not find untracked data directory"
**Solution:**
```bash
# Specify exact path
python scripts/setup_data.py --source-dir /path/to/OAI_untracked

# Or check common locations
ls ~/Documents/OAI_untracked
ls ~/Downloads/OAI_untracked
```

#### "Insufficient disk space"
**Solution:**
```bash
# Check available space
df -h

# Clean up unnecessary files
# Pretrained models are optional - you can skip them
python scripts/setup_data.py --source-dir /path/to/OAI_untracked
```

#### "Permission denied"
**Solution:**
```bash
# Fix permissions
chmod -R 755 .

# Or use sudo (not recommended)
sudo python scripts/setup_data.py
```

### General Issues

#### "Image count mismatch"
**Expected:** 539 PNG files in `data/oai/img/`

**Check:**
```bash
ls data/oai/img/*.png | wc -l  # Should show 539
```

**File naming convention:**
- `6.C.1_*.png` - OAI project code 6, visit C.1 (could be low or high BMD)
- `6.E.1_*.png` - OAI project code 6, visit E.1 (could be low or high BMD)
- BMD classification (low vs high) is determined by median threshold, not filename
- See `data.csv` for actual BMD values and classifications

#### "Model files missing"
**Solution:**
- Pretrained models are optional
- Download from source if needed
- Missing models will show as "skipped" in comprehensive test
- Training will use random initialization without pretrained weights

#### "Out of memory errors"
**Solution:**
```bash
# Reduce batch size in config
# configs/oai_config.yml
training:
  batch_size: 4  # Reduced from 8

# Or use smaller image size
training:
  image_size: 256  # Reduced from 512
```

#### "Import errors"
**Solution:**
```bash
# Ensure virtual environment is activated
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows

# Reinstall dependencies
pip install -e ".[dev,ml]"

# Check Python path
python -c "import sys; print('\n'.join(sys.path))"
```

#### "CUDA/GPU not available"
**Solution:**
```bash
# Check PyTorch CUDA
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# In Colab: Enable GPU
# Runtime ‚Üí Change runtime type ‚Üí GPU

# Reinstall PyTorch with CUDA support
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### Getting Help

If you're still experiencing issues:

1. **Check existing issues**: [GitHub Issues](https://github.com/johnreynolds3d/OAI-inpainting/issues)
2. **Review error logs**: Check `results/logs/` for detailed error messages
3. **Create new issue**: Include:
   - Error message (full traceback)
   - Steps to reproduce
   - Environment details (OS, Python version, GPU)
   - Configuration files used

---

## ü§ù Contributing

We welcome contributions! See [docs/contributing.md](docs/contributing.md) for detailed guidelines.

### Quick Contributing Guide

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes
4. Run tests: `pytest tests/`
5. Run linting: `ruff check . --fix`
6. Commit changes: `git commit -m 'Add amazing feature'`
7. Push to branch: `git push origin feature/amazing-feature`
8. Open a Pull Request

### Development Setup

```bash
# Clone your fork
git clone https://github.com/YOUR_USERNAME/OAI-inpainting.git
cd OAI-inpainting

# Install dev dependencies
pip install -e ".[dev,ml]"

# Install pre-commit hooks
pre-commit install

# Run tests
pytest tests/
```

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### Third-Party Licenses

This project includes third-party models and code with their own licenses:

- **AOT-GAN**: Apache 2.0 License
- **RePaint**: MIT License + CC BY-NC-SA 4.0 (Huawei)
- **ICT**: Research use only

Please review the individual license files in the `models/` directory for specific terms.

### Research Use

This project is intended for **academic research and educational purposes**. The OAI dataset is used under appropriate research agreements. Commercial use may require additional permissions from third-party licensors.

---

## üôè Acknowledgments

- Original AOT-GAN, ICT, and RePaint implementations
- OAI (Osteoarthritis Initiative) dataset providers
- Open source community
- Contributors and maintainers

---

## üìû Support

- **Issues**: [Create an issue](https://github.com/johnreynolds3d/OAI-inpainting/issues)
- **Discussions**: [GitHub Discussions](https://github.com/johnreynolds3d/OAI-inpainting/discussions)
- **Documentation**: See [docs/](docs/) directory
- **Email**: [Contact information]

---

## üîÑ Version History

- **v1.4.0** (Current)
  - Added comprehensive testing script for all model variants
  - Consolidated documentation into single README
  - Improved Google Colab integration with Git pulling
  - Enhanced error handling and progress tracking

- **v1.3.0**
  - Comprehensive evaluation framework
  - Statistical significance testing
  - Improved visualization tools

- **v1.2.0**
  - Platform-agnostic configuration system
  - Unified data management
  - Pre-commit hooks integration

- **v1.1.0**
  - Unified scripts for training/testing
  - Improved documentation
  - Google Colab support

- **v1.0.0**
  - Initial release
  - Three inpainting models implemented
  - Basic evaluation metrics

---

**Note**: This project is designed for research purposes. Ensure compliance with medical imaging regulations and ethical guidelines when using X-ray data.

---

Made with ‚ù§Ô∏è for medical image analysis research
